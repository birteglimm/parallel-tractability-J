
%\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
 \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
\usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}

\usepackage{amsmath}

\usepackage{CJK}
\usepackage{color}

\usepackage{enumitem}
\usepackage{rotating}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

%\journal{Nuclear Physics B}

\hyphenation{data-log}

\begin{document}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{Parallel Tractability of Ontology\\
Materialization: Technique and Practice}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \address[label1]{}
%% \address[label2]{}

\author{}

\address{}

\begin{abstract}
Materialization is an important reasoning service for applications built
on the ontology languages, such as OWL. With a
rapid growth of semantic data, it is challenging to perform
materialization on large-scale ontologies efficiently.
Current work proposes parallel algorithms and employs computing
platforms of high-performance to make materialization sufficiently efficient and scalable in practice.
However, there do exist ontologies, for which
materialization cannot always be improved by parallelism (we use experiments to show it in Section~\ref{sec:evaluation}).
On the other hand, some well-known large-scale ontologies, such as YAGO, have been shown to have
good performance for parallel reasoning, but they are expressed in ontology languages
that are not parallelly tractable in theory, i.e., the efficiency of reasoning may not be improved
on a parallel implementation.
This motivates us to study the problem of \emph{parallel tractability} of ontology
materialization from a theoretical perspective.
That is, we aim to identify the ontologies for which materialization is
parallelly tractable, i.e., in \texttt{NC} complexity.
The results of the parallel tractability can be further used to optimize
materialization algorithms and to guide ontology engineers in creating parallelly tractable ontologies.

In this work, we focus on datalog rewritable ontology languages.
We propose some algorithms, called \texttt{NC} algorithms, to identify several classes of datalog rewritable
ontologies (called \emph{parallelly tractable classes})
such that materialization over them is parallelly tractable.
We then investigate the parallel tractability of materialization over
two datalog rewritable ontology languages DL-Lite and DHL (\emph{Description Horn Logic}).
We show that materialization over any ontology expressed in DL-Lite$_{core}$ or DL-Lite$_\mathcal{R}$ is parallelly tractable.
For DHL, there exist ontologies where materialization can hardly be parallelized.
We propose to restrict the usage of DHL such that the restricted ontologies are parallelly tractable.
We further extend the results to an extension of DHL that also allows \emph{complex role inclusion axioms}.
To verify the practical usability of the above results, we analyze real-world datasets and show
that many ontologies expressed in DHL or its extension belong to
the parallelly tractable classes. Based on the results of parallel tractability,
we further implement an optimized parallel algorithm
and compare it to the state-of-the-art reasoner RDFox. The experimental results show that the
optimization used in our implementation results in a better
performance on parallelly tractable ontologies compared with RDFox.
\end{abstract}

\begin{keyword}
ontology \sep materialization \sep datalog \sep parallel tractability \sep \texttt{NC} complexity
\end{keyword}

\end{frontmatter}

%% \linenumbers


\section{Introduction}
\label{sec:introduction}

The Web Ontology Language (OWL)\footnote{The latest version is OWL 2: http://www.w3.org/TR/owl2-overview/}
is an important standard for ontology language in the Semantic Web and knowledge-based applications.
In these applications, \emph{materialization}, which is the reasoning task of computing all implicit
facts that follow from a given ontology \cite{handbook}, plays an important role. By means of it, developers and users
can optimize query answering, ontology diagnosis and debugging. Since huge amounts of semantic data
are being generated at an increasing pace by sensor networks, government authorities and social
media \cite{LehmbergRMB16,MeuselBP15}, it is challenging to conduct materialization on such large-scale ontologies efficiently.

There has been work that proposes parallel algorithms and employs parallel computing platforms for the ontology language RDFS and its extended
fragments \cite{MotikNPHO14,PetersSZ15,SubercazeGCL16}. Several optimization strategies, e.g., dictionary encoding, balance workload,
data partitioning, are further studied to enhance parallel RDFS reasoning. There are also parallel implementations for scalable
reasoning of highly expressive ontology languages \cite{SteigmillerLG14,WuH12}. On the other hand, in order to make reasoning tasks more efficient
in parallel, several work utilizes different kinds of high-performance computing platforms, like supercomputers \cite{Hoeksema2011,GoodmanJMAAH11},
MapReduce \cite{UrbaniKMHB12} and GPU servers \cite{HeinoP12}.

The above work verifies the effectiveness of parallel reasoning based on the evaluations on different test datasets.
However, for most popular ontology languages, even RDFS and datalog rewritable ontology languages,
which have \texttt{PTime}-complete or higher complexity of reasoning in the worst case,
they are not parallelly tractable according to \cite{Raymond95}, i.e., the efficiency of reasoning may not be
improved on a parallel implementation. A possible reason of the high performance of parallel
reasoning is that the utilized test datasets do not fall in the worst cases in terms of computational complexity.
It has also been shown that, some well-known large-scale ontologies, such as YAGO, have good performance for parallel
reasoning \cite{KolovskiWE10}, but they are expressed in ontology languages that are not parallelly tractable in theory.
On the other hand, we show in Section~\ref{sec:evaluation} that, there do exist some ontologies, for which materialization cannot
always be improved by parallelism. The current work of parallel ontology reasoning can hardly explain this.
While one can try out different parallel implementations to see whether an ontology can be handled by (one of) them efficiently,
we study the problem of parallel tractability in theory and identify properties that make an ontology parallelly tractable.
These properties can be further used to optimize parallel algorithms and to guide ontology engineers in creating ontologies
for which parallel tractability can be guaranteed theoretically.

According to \cite{MotikNPHO14}, many real large-scale ontologies are essentially expressed in the ontology languages
that can be rewritten into datalog rules. Thus, we focus on such datalog rewritable ontology languages in this paper.
The main target of this paper is to identify the classes of datalog rewritable ontologies such that materialization
over these ontologies is parallelly tractable, i.e., in the parallel complexity class $\texttt{NC}$ \cite{Raymond95}.
This complexity class consists of problems that can be solved efficiently in parallel.
To show that a problem is in the \texttt{NC} class, one can give an \emph{\texttt{NC} algorithm} that handles this problem
in parallel computation \cite{Raymond95}.
An \texttt{NC} algorithm is required to terminate in parallel poly-logarithmic time.
However, current materialization algorithms of datalog rewritable ontology languages
(e.g., the core algorithm used in RDFox \cite{MotikNPHO14}) are not \texttt{NC} algorithms,
since they are designed for general datalog programs and has \texttt{PTime}-complete complexity.
Thus, we first give \texttt{NC} algorithms that perform materialization,
and then identify the corresponding classes of datalog rewritable ontologies (called \emph{parallelly tractable classes})
that can be handled by these \texttt{NC} algorithms. To make the proposed \texttt{NC} algorithms practical,
we also discuss how to optimize and implement them.

In the practical part of this work, we study specific datalog rewritable ontology languages.
We first focus on the ontology language DL-Lite to clarify how to apply the above \texttt{NC} algorithms
to study the parallel tractability of ontology materialization.
We show that DL-Lite$_{core}$ and DL-Lite$_\mathcal{R}$ are parallelly tractable.
We then study the ontology language Description Horn Logic (DHL) \cite{GrosofHVD03}, which is the intersection of datalog and OWL
in terms of expressivity. We give a case of a DHL ontology where materialization can hardly be parallelized.
Based on the analysis of this case, we propose to restrict the usage of DHL such that materialization over the
restricted ontologies can be handled by the proposed \texttt{NC} algorithms.
We further extend the results to an extension of DHL that also allows complex role inclusion axioms.
Finally, we analyze well-known benchmarks and real-world datasets and show that many real ontologies following the
proposed restrictions belong to the parallelly tractable classes.
We implement a system based on an optimized \texttt{NC} algorithm for DHL materialization.
We compare our system to the state-of-the-art reasoner RDFox.
The experimental results show that the optimization proposed in this paper results in a better performance on parallelly
tractable ontologies compared with RDFox.

The rest of the paper is organized as follows. In Section~\ref{sec:background}, we introduce some basic notions.
We then give two \texttt{NC} algorithms for ontology materialization in Section~\ref{sec:ptclass}.
We study the parallelly tractable materialization of DL-Lite, DHL and an extension of DHL in Section~\ref{sec:ptonto} respectively.
In Section~\ref{sec:practicalAlg},
we discuss how to optimize and implement the given \texttt{NC} algorithms.
We analyze real-world datasets and evaluate our implementation in Section~\ref{sec:evaluation}.
We then discuss related work in Section~\ref{sec:related} and conclude in Section~\ref{sec:conclusion}.


\section{Background Knowledge}
\label{sec:background}

In this section, we introduce some basic notions that are needed to introduce our approach.

\subsection{Datalog}

We discuss the main issues in this paper using standard datalog notions.
In datalog \cite{database}, a \emph{term} is a variable or a constant. An \emph{atom} $A$
is defined by $A\equiv p(t_1,...,t_n)$ where $p$ is a \emph{predicate} (or \emph{relational})
name, $t_1,...,t_n$ are terms, and $n$ is the arity of $p$. If all the terms in an atom $A$ are
constants, then $A$ is called a \emph{ground atom}.
A datalog \emph{rule} is of the form: `$B_1,...,B_n\rightarrow H$',\footnote{In datalog rules, a comma
represents a Boolean conjunction `$\wedge$'.} where $H$ is referred to as
the \emph{head atom} and $B_1,...,B_n$ the \emph{body atoms}. Each variable in the head atom
of a rule must occur in at least one body atom of the same rule. A \emph{fact} is a rule of
the form `$\rightarrow H$', i.e., a rule with an empty body and the head $H$ being a ground atom.
A datalog program $P$ consists of rules and facts.
A \emph{substitution} $\theta$ is a partial mapping of variables to constants.
For an atom $A$, $A\theta$ is the result of replacing each variable $x$ in $A$
with $\theta(x)$ if the latter is defined. We call $\theta$ a \emph{ground substitution}
if each defined $A\theta$ is a ground atom.
A \emph{ground instantiation} of a rule is obtained by applying a ground substitution on all
the terms in this rule with respect to a finite set of constants occurring in $P$.
Furthermore the ground instantiation of $P$, denoted by $P^*$,
consists of all ground instantiations of rules in $P$.
The predicates occurring only in the body  of some rules are called \emph{EDB predicates},
while the predicates that may occur as head atoms are called \emph{IDB predicates}.

\subsection{DHL and DL-Lite}

In what follows, we use $\textbf{CN}$, $\textbf{RN}$ and $\textbf{IN}$
to denote three disjoint countably
infinite sets of \emph{concept names, role names}, and \emph{individual names} respectively.
The set of roles is defined as $\textbf{R}:=\textbf{RN}\cup\{R^-|R\in\textbf{RN}\}$
where $R^-$ is the \emph{inverse role} of $R$.
For ease of discussion, we focus on the \emph{simple forms} of axioms shown
in the left column of Table~1. These simple forms can be obtained by using
well-known \emph{structure transformation} techniques \cite{KrotzschRH07,Kazakov09}.

DHL (short for \emph{description horn logic}) \cite{GrosofHVD03} is introduced as an
intersection of description logic (DL) and datalog in terms of expressivity.
We define a DHL ontology $\mathcal{O}$ as a triple:
$\mathcal{O}=\langle\mathcal{T},\mathcal{R},\mathcal{A}\rangle$, where
$\mathcal{T}$ denotes the TBox containing axioms of the forms (T1-T3);
$\mathcal{R}$ is the RBox that is a set of axioms of the forms (R1-R3);
$\mathcal{A}$ is the ABox containing \emph{assertions} of the forms (A1) and (A2).
In an axiom of either of  the forms (T1-T3 and R1-R3), concepts $A_{(i)}$ and $B$ are either
concept names, \emph{top concept} ($\top$) or \emph{bottom concept} ($\bot$); $R$ and $S_{(i)}$
are roles in $\textbf{R}$.
For an axiom of the form $A\sqsubseteq\forall R.B$ that is also allowed in DHL, we only consider its
equivalent form $\exists R^-.A\sqsubseteq B$.

DHL is related with other ontology languages.
First, DHL is essentially a fragment of the description logic Horn-$\mathcal{SHOIQ}$ with
disallowing \emph{nominal}, \emph{number restriction} and
right-hand \emph{existential restriction} ($A\sqsubseteq\exists R.B$).
Second, the expressivity of DHL covers that of RDFS to some extent \cite{GrosofHVD03}.
Reasoning with RDFS ontologies is \texttt{NP}-complete \cite{Horst05}
and, thus, is not parallelly tractable.
However, by applying some simplifications and restrictions, RDFS ontologies can be
expressed in DHL \cite{GrosofHVD03} that has \texttt{PTime}-complete complexity for
materialization.

\begin{table}
\begin{center}
\begin{tabular}{lcc}
\multicolumn{3}{c}{\textbf{Table 1: Axioms and corresponding datalog rules}}\\
\hline
&~~~~~~~~~~~~~~~~~~~~~~~~Axioms~~~~~~~~~~~~~~~~~~~~~~~~&~~~~~~~~~~~~~~~~~~~~~~~~Datalog Rules~~~~~~~~~~~~~~~~~~~~~~~~\\
\hline
\hline
(T1)& $A\sqsubseteq B$& $A(x)\rightarrow B(x)$\\
(T2)& $A_1\sqcap A_2\sqsubseteq B$& $A_1(x), A_2(x)\rightarrow B(x)$\\
(T3)& $\exists R.A\sqsubseteq B$& $R(x,y), A(y)\rightarrow B(x)$\\
(T4)& $A\sqsubseteq\exists R$& $A(x)\rightarrow R(x, o_{R}^A)$\\

\hline
(R1)& $S\sqsubseteq R$& $S(x,y)\rightarrow R(x,y)$\\
(R2)& $S\sqsubseteq R^-$& $S(x,y)\rightarrow R(y,x)$\\
(R3)& $R\circ R\sqsubseteq R$& $R(x,y), R(y,z)\rightarrow R(x,z)$\\
(R4)& $R_1\circ R_2\sqsubseteq R$&$R_1(x,y),R_2(y,z)\rightarrow R(x,z)$\\

\hline
(A1)& $A(a)$& $A(a)$\\
(A2)& $R(a,b)$& $R(a,b)$\\
\hline
\end{tabular}
\label{tab:dhl}
\end{center}
\end{table}

In the initial work of DHL \cite{GrosofHVD03}, \emph{complex role inclusion axioms} (complex RIAs) of
the form $R_1\circ...\circ R_n\sqsubseteq R$ are not considered, although they can be
naturally transformed to datalog rules.
In this paper, we also consider an extension of DHL (denoted by DHL($\circ$))
that allows complex RIAs. Since a complex RIA can be transformed to
several axioms of the form (R4), we then require that an
RBox $\mathcal{R}$ of a DHL($\circ$) ontology can contain
axioms of the forms (R1-R4). Note that (R3) is actually a special
case of (R4).

DL-Lite is a group of ontology languages designed for highly-efficient
query answering through knowledge
and underpins the OWL profile OWL QL \cite{CalvaneseGLLR07}.
DL-Lite$_{core}$ and DL-Lite$_{\mathcal{R}}$ are the two basic fragments
in DL-Lite.
DL-Lite$_{core}$ requires that an TBox contains axioms of the forms (T1) $A\sqsubseteq B$,
(T2) $A_1\sqcap A_2\sqsubseteq B$ where $B\equiv\bot$, (T3) $\exists R.A\sqsubseteq B$
where $A\equiv\top$ or $B\equiv\bot$, and (T4) $A\sqsubseteq\exists R$,
an ABox contains \emph{assertions} of the forms (A1) and (A2), and
RBox is not involved. DL-Lite$_{\mathcal{R}}$ is an extension of DL-Lite$_{core}$,
which allows involving RBoxes that contain axioms of the forms (R1-R2).
If not specially specified, \emph{a DL-Lite ontology denotes a DL-Lite$_{\mathcal{R}}$ ontology
in the following paragraphs}.

\subsection{Ontology Materialization via Datalog Programs}

An ontology
expressed in DHL, DHL($\circ$), DL-Lite$_{core}$ or DL-Lite$_{\mathcal{R}}$ can be transformed to a datalog program
(see the corresponding rules in the right column of Table~1).
Note that, for an axiom of the form (T4) $A\sqsubseteq\exists R$, it should be transformed to
a first-order logic rule `$A(x)\rightarrow \exists y(R(x,y))$' where $y$ is a free variable.
In this work, such a free variable $y$ is eliminated via Skolemisation into a new individual $o_{R}^A$
that corresponds to concept $A$ and role $R$. One can check that the elimination of free variables
does not influence the results of materialization by according to \cite{CalvaneseGLLR07}.

In what follows, for an ontology $\mathcal{O}=\langle\mathcal{T},\mathcal{R},\mathcal{A}\rangle$,
we also use $P=\langle R, \textbf{I}\rangle$ to represent the corresponding datalog program
where $R$ is the set of rules transformed from the axioms in $\mathcal{T}$ and $\mathcal{R}$,
$\textbf{I}$ is the set of facts that are directly copied from the assertions in $\mathcal{A}$.
Further, we use $R_1\sqsubseteq_{*}R_2$ to denote the smallest transitive reflexive relation
between roles such that $R_1\sqsubseteq R_2\in\mathcal{R}$ implies $R_1\sqsubseteq_{*}R_2$
and $R_1^-\sqsubseteq_{*}R_2^-$. In this paper, we also use the
notion of \emph{simple role}, which is initially proposed to restrict the
usage of highly expressive ontology languages \cite{HorrocksS04}.
Specifically, a role $S\in\textbf{R}$ is \emph{simple} if, (1) it has no subrole (including $S$)
occurring on the right-hand side of axioms of the forms (R3) and (R4); (2) $S^-$ is simple.

Based on the above representations, ontology materialization
corresponds to the evaluation of datalog programs.
Specifically, given a datalog program $P=\langle R, \textbf{I}\rangle$,
let $T_R(\textbf{I})=\{H\theta|\forall B_1,...,B_n\rightarrow H\in R, B_i\theta\in\textbf{I} (1\leq i\leq n)\}$,
where $\theta$ is some substitution; further let $T_R^{0}(\textbf{I})=\textbf{I}$ and
 $T_R^{i}(\textbf{I})=T_R^{i-1}(\textbf{I})\cup T_R(T_R^{i-1}(\textbf{I}))$ for each $i>0$.
The smallest integer $n$ such that $T_R^{n}(\textbf{I})= T_R^{n+1}(\textbf{I})$ is called \emph{stage},
and \emph{materialization} refers to the computation of $T_R^{n}(\textbf{I})$ with respect to $R$ and \textbf{I}.
$T_R^{n}(\textbf{I})$ is also called the \emph{fixpoint} and denoted by $T_R^{\omega}(\textbf{I})$.
We say that an atom $A$ is \emph{derivable} or can be \emph{derived} with respect
to the datalog program $P=\langle R, \textbf{I}\rangle$ if $A\in T_R^{\omega}(\textbf{I})$.
In this paper, we consider the data complexity of materialization, i.e., we \emph{assume that the rule set $R$ is fixed}.

\subsection{The $\texttt{NC}$ Complexity}

The parallel complexity class $\texttt{NC}$, known as Nick$'$s
Class \cite{Raymond95}, is studied by theorists as a parallel complexity class
where each decision problem can be efficiently solved in parallel.
Specifically, a decision problem in the $\texttt{NC}$ class
can be solved in poly-logarithmic time on a parallel machine with a polynomial number of processors.
We also say that an $\texttt{NC}$ problem can be solved in \emph{parallel poly-logarithmic time}.
Although the $\texttt{NC}$ complexity is a theoretical analysis tool,
it has been shown that many $\texttt{NC}$ problems can be solved efficiently in practice \cite{Raymond95}.

From the perspective of implementations, the $\texttt{NC}$ problems are also highly
parallel feasible for other parallel models like BSP \cite{Valiant90}
and MapReduce \cite{KarloffSV10}. The \texttt{NC} complexity is originally defined
as a class of decision problems. Since we study the problem of materialization, we do not
require in this work that a problem should be a decision problem in $\texttt{NC}$.
In addition, since many parallel reasoning systems (see related work in Section~\ref{sec:related})
are implemented on shared-memory platforms, we
study all the issues in this work by assuming that the running machines are in
shared-memory configurations.


\section{Parallel Tractability of Datalog Programs}
\label{sec:ptclass}

Our target is to find for which kinds of ontologies (not ontology languages)
materialization is parallelly tractable.
Since we assume that for any datalog program $\langle R, \textbf{I}\rangle$ the rule
set $R$ is fixed, the materialization problem is thus in data complexity
$\texttt{PTime}$-complete, which is considered to be inherently sequential in the worst
case \cite{Raymond95}. In other words, the materialization problem on general
datalog programs cannot be solved in parallel poly-logarithmic time unless \texttt{P}=\texttt{NC}.
Thus, we say that \emph{materialization on a class of datalog programs is parallelly tractable
if there exists an algorithm that handles this class of datalog programs and runs in parallel
poly-logarithmic time (this algorithm is also called an \texttt{NC} algorithm)}.
In this section, we identify such classes of datalog programs by studying different \texttt{NC} algorithms.


\subsection{Parallel Tractable Classes}

We first give the following definition for a parallel tractable class of datalog programs
where an \texttt{NC} algorithm exists for handling each datalog program in this class.

\begin{definition}\label{def:ptd}
\textbf{(Parallelly Tractable Class)} Given a class $\mathcal{D}$ of datalog programs,
we say that $\mathcal{D}$ is a parallelly tractable datalog program (\texttt{PTD}) class
if there exists an \texttt{NC} algorithm that performs sound and complete materialization for each datalog program
in $\mathcal{D}$. The corresponding class of ontologies of $\mathcal{D}$ is called a
parallelly tractable ontology (\texttt{PTO}) class.
\end{definition}

According to the above definition, if we find an \texttt{NC} algorithm $\mathsf{A}$
for datalog materialization, then we can identify a \texttt{PTD} class $\mathcal{D}_{\mathsf{A}}$,
which is the class of all datalog programs that can be handled by $\mathsf{A}$.
However, current materialization algorithms of datalog rewritable ontology languages
(e.g., the core algorithm used in RDFox \cite{MotikNPHO14}) are not \texttt{NC} algorithms
due to their \texttt{PTime}-complete complexity, since they are designed for handling general datalog programs.
Thus we give our $\texttt{NC}$ algorithms.
In the following, we first give a parallel materialization algorithm that works for
general datalog programs. We then restrict this algorithm to an \texttt{NC} version
and identify the target \texttt{PTD} class.


\subsection{Materialization Graph}

In order to give a parallel materialization algorithm,
we introduce the notion of \emph{materialization graph}.
It makes the analysis of the given algorithm convenient.

\begin{definition}
\textbf{(Materialization Graph)}\label{def:mg}
A \emph{materialization graph}, with respect to
a datalog program $P=\langle R, \textbf{I}\rangle$, is a directed acyclic graph
denoted by $\mathcal{G}=\langle V, E\rangle$ where,
\begin{enumerate}[leftmargin=4ex,label=$\bullet$]
  \item $V$ is the node set and $V\subseteq T_R^{\omega}(\textbf{I})$;
  \item $E$ is the edge set and $E\subseteq T_R^{\omega}(\textbf{I})\times T_R^{\omega}(\textbf{I})$;
\end{enumerate}
~~$\mathcal{G}$ satisfies the following condition:
\begin{enumerate}[leftmargin=4ex,label=$\bullet$]
  \item $\forall H,B_1,...,B_n\in V$ such that $e(B_1, H),...,e(B_n, H)\in E$ and
  $B_1,...,B_n$ are \d{all} the parents of $H$, we have that
  $B_1,...,B_n\rightarrow H\in P^*$.
\end{enumerate}
\end{definition}

For some derived atom $H$, there may exist several rule instantiations where $H$
occurs as a head atom.
This also means that $H$ can be derived in different ways.
The condition in the definition above results in only one way of deriving $H$ being
described by a materialization graph.
Suppose $\mathcal{G}$ is a materialization graph, the nodes whose in-degree is 0 are the
original facts in $\textbf{I}$.
The size of $\mathcal{G}$, denoted by $|\mathcal{G}|$, is the number of nodes in $\mathcal{G}$.
The depth of $\mathcal{G}$, denoted by \texttt{depth}($\mathcal{G}$), is the maximal length of a path
in $\mathcal{G}$.
We next give an example of a materialization graph.\\

\begin{example}\label{exp:mg}
Consider a DHL($\circ$) ontology $\mathcal{O}_{ex_1}$ where the TBox is
$\{\exists R.A\sqsubseteq A\}$, the RBox is $\{S\circ R\sqsubseteq R\}$ and
the ABox is $\{A(b),R(a_1,b),S(a_i,a_{i-1})\}$ for $2\leq i\leq k$ and
$k$ is an integer greater than $2$.
The corresponding datalog program of this ontology is $P_{ex_1}=\langle R, \textbf{I}\rangle$
where $\textbf{I}$ contains all the assertions in the ABox
and $R$ contains the two rules `$R(x,y),A(y)\rightarrow A(x)$'
and `$S(x,y),R(y,z)\rightarrow R(x,z)$'.
The graph in Figure~\ref{fig:mg} is a materialization graph with respect to $P_{ex_1}$,
denoted by $\mathcal{G}_{ex_1}$.
The nodes whose in-degree is 0 are the original facts in $\textbf{I}$;
each of the other nodes corresponds to a ground instantiation of some rule.
For example, the node $A(a_k)$ corresponds to the ground rule instantiation
`$R(a_k,b),A(b)\rightarrow A(a_k)$'.
The size of this materialization graph is the number of nodes, that is $3k$.
The depth of $\mathcal{G}_{ex_1}$ is $k$.
\end{example}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.7\textwidth]{fig-mg.eps}
\caption{An example of a materialization graph.}
\label{fig:mg}
\end{center}
\end{figure}

We say that a materialization graph $\mathcal{G}$ is a \emph{complete materialization graph}
when $\mathcal{G}$ contains all ground atoms in $T_R^{\omega}(\textbf{I})$.
The set of nodes in a complete materialization graph is actually the result
of materialization.
Thus, the procedure of materialization can be transformed to the construction of
a complete materialization graph.
We pay our attention to complete materialization graphs and do not distinguish it to the
notion `materialization graph'.
It should also be noted that there may exist several materialization graphs for a datalog program.

\subsection{A Basic Parallel Algorithm}

In this part, we propose a parallel algorithm
(denoted by $\mathsf{A}_{bsc}$) that constructs a materialization graph for a given datalog program.\\

\noindent\texttt{Algorithm $\mathsf{A}_{bsc}$}. Given a datalog program $P=\langle R, \textbf{I}\rangle$,
the algorithm returns a materialization graph $\mathcal{G}$ of $P$.
Recall that $P^*$ denotes the ground instantiation of $P$,
which consists of all possible ground instantiations of rules in $R$.
Suppose we have $|P^*|$ processors, and each rule instantiation in $P^*$ is
assigned to one processor.\footnote{This might not be practically feasible,
but we focus on a theoretical analysis here.}
Initially $\mathcal{G}$ is empty. The following three steps are then performed:
\begin{enumerate}[leftmargin=8ex,label=(\textit{Step \arabic*}),ref=Step~\arabic*]
\item Add all facts in $\textbf{I}$ to $\mathcal{G}$.\label{alg1:addFacts}
\item For each rule instantiation $B_1,...,B_n\rightarrow H$, if the body atoms are all
    in $\mathcal{G}$ while $H$ is not in $\mathcal{G}$,\footnote{Suppose that each processor
    can use $O(1)$ time units to access the state of ground atoms, i.e., whether this ground
    atom has been added to the materialization graph. This can be implemented by maintaining an
    index of polynomial size.}
    the corresponding processor adds $H$ to $\mathcal{G}$ and creates edges pointing
    from $B_1,...,B_n$ to $H$.\label{alg1:updateG}
\item If no processor can add more nodes and edges to $\mathcal{G}$, terminate, otherwise iterate \ref{alg1:updateG}.\label{alg1:halt}\hfill$\Box$
\end{enumerate}

\begin{example}
We consider the datalog program $P_{ex_1}$ in Example~\ref{exp:mg} again,
and perform Algorithm~$\mathsf{A}_{bsc}$ on it.
Initially, all the facts ($A(b),R(a_1,b),S(a_2,a_1),...,S(a_{k},a_{k-1})$) are added to the
result $\mathcal{G}_{ex_1}$ (\ref{alg1:addFacts}).
Then in different iterations of \ref{alg1:updateG}, the remaining nodes are added to
$\mathcal{G}_{ex_1}$ by different processors.
For example a processor $p$ is allocated a rule instantiation `$R(a_2,b),A(b)\rightarrow A(a_2)$'.
Then, processor $p$ adds $A(a_2)$ to $\mathcal{G}_{ex_1}$ after it checks that
$A(b)$ and $R(a_2,b)$ are in $\mathcal{G}_{ex_1}$.
Algorithm~$\mathsf{A}_{bsc}$ halts when $A(a_k)$ has been added to $\mathcal{G}_{ex_1}$ (\ref{alg1:halt}).
\end{example}

Lemma~\ref{lemma:a1} shows the correctness of Algorithm~$\mathsf{A}_{bsc}$ and that, for any datalog program $P$,
Algorithm~$\mathsf{A}_{bsc}$ always constructs a materialization graph with the minimum depth among all the
materialization graphs of $P$. The detailed proofs of Lemma~\ref{lemma:a1} and other lemmas and theorems can be found
in the appendix.

\begin{lemma}
\label{lemma:a1}
Given a datalog program $P=\langle R, \textbf{I}\rangle$, we have
\begin{enumerate}[leftmargin=4ex]
\item Algorithm~$\mathsf{A}_{bsc}$ halts and returns a materialization graph $\mathcal{G}$ of $P$;
\item $\mathcal{G}$ has the the minimum depth among all the materialization graphs of $P$.
\end{enumerate}
\end{lemma}

\begin{proof}[Proof sketch] This lemma can be proved by performing
an induction on $T_R^{\omega}(\textbf{I})$.
The stage (see the related contents in Section~\ref{sec:background}) of $P$
is the lower-bound of the depth of the materialization graphs. Based on the previous induction,
one can further check that, for the materialization graph $\mathcal{G}$ constructed by Algorithm~$\mathsf{A}_{bsc}$,
its depth equals the depth of the stage.
\end{proof}

We now discuss how Algorithm~$\mathsf{A}_{bsc}$ can be restricted to an \texttt{NC} version.
(\uppercase\expandafter{\romannumeral1}) Since Algorithm~$\mathsf{A}_{bsc}$ does not introduce
new constants and each predicate has a constant arity,
one can check that $|P^*|$ is polynomial in the size of $P$. This also means that
the number of processors is polynomially bounded.
(\uppercase\expandafter{\romannumeral2}) The computing time of \ref{alg1:addFacts}
and \ref{alg1:halt} occupies constant time units because of parallelism.
(\uppercase\expandafter{\romannumeral3}) The main computation part in Algorithm~$\mathsf{A}_{bsc}$ is the
iteration of \ref{alg1:updateG}.
In each iteration of \ref{alg1:updateG}, all processors work independently from each other.
Thus, in theory, \ref{alg1:updateG} costs one time unit.
The whole computing time turns out to be bounded by the number of iterations of \ref{alg1:updateG}. (\uppercase\expandafter{\romannumeral4})
We use the symbol $\psi$ to denote a poly-logarithmically bounded function.
The input of $\psi$ is the size of $P$ and the output is a non-negative integer.
Based on (\uppercase\expandafter{\romannumeral1}, \uppercase\expandafter{\romannumeral2},
\uppercase\expandafter{\romannumeral3}, \uppercase\expandafter{\romannumeral4}),
for any datalog program $P$, if we use $\psi(|P|)$ to
bound the number of iterations of \ref{alg1:updateG}, then Algorithm~$\mathsf{A}_{bsc}$
is an \texttt{NC} algorithm, denoted by $\mathsf{A}_{bsc}^{\psi}$ (this symbol also
means that $\psi$ occurs as a configuration for Algorithm~$\mathsf{A}_{bsc}$).

Based on $\mathsf{A}_{bsc}^{\psi}$, we can identify a class of datalog programs
$\mathcal{D}_{\mathsf{A}_{bsc}^{\psi}}$ such that all the datalog programs in it can be handled
by $\mathsf{A}_{bsc}^{\psi}$.
It is obvious that $\mathcal{D}_{\mathsf{A}_{bsc}^{\psi}}$ is a \texttt{PTD} class.
We use the following theorem to further show that this class can be captured based on
the materialization graphs of the datalog programs in $\mathcal{D}_{\mathsf{A}_{bsc}^{\psi}}$.

\begin{theorem}\label{theorem:a1}
For any datalog program $P$, $P\in\mathcal{D}_{\mathsf{A}_{bsc}^{\psi}}$ iff $P$ has a
materialization graph whose depth is upper-bounded by $\psi(|P|)$.
\end{theorem}

\begin{proof}[Proof sketch]
We can first prove that the number of iterations
of \ref{alg1:updateG} is actually the depth of the constructed materialization
graph. This theorem then follows by considering
Lemma~\ref{lemma:a1}.
\end{proof}

The algorithm $\mathsf{A}_{bsc}^{\psi}$ is restricted in the sense that it cannot even work on the
rather simple datalog program $P_{ex_1}$ in Example~\ref{exp:mg}.
The graph $\mathcal{G}_{ex_1}$ in Figure~\ref{fig:mg} is the unique materialization graph of $P_{ex_1}$.
One can also check that \texttt{depth}($\mathcal{G}_{ex_1}$)$=k$.
This means that the depth of $\mathcal{G}_{ex_1}$ is linearly bounded by $k$.
On the other hand, the size of $P_{ex_1}$ is a polynomial of the integer $k$.
Thus, for any $\psi$ that is poly-logarithmically bounded, we can always find a $k$ large
enough such that $\mathsf{A}_{bsc}^{\psi}$ terminates without constructing a materialization
graph of $P_{ex_1}$.
However there indeed exists an \texttt{NC} algorithm that can handle $P_{ex_1}$.
We discuss this in the next part.

\subsection{Optimizing Algorithm~$\mathsf{A}_{bsc}$ via the Single-Way Derivability}

In this part, we optimize Algorithm~$\mathsf{A}_{bsc}$ such that $P_{ex_1}$
can be handled. Based on the optimized variant of Algorithm~$\mathsf{A}_{bsc}$,
we can identify another \texttt{PTD} class.

We discuss our optimization based on a specific case in Example~\ref{exp:general}.
We find that, in this kind of case, the construction of a materialization graph can be accelerated.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.7\textwidth]{fig-general.eps}
\caption{A partial materialization graph.}
\label{fig:general}
\end{center}
\end{figure}

\begin{example}\label{exp:general}
Consider a snapshot of Algorithm~$\mathsf{A}_{bsc}$ in
Figure~\ref{fig:general}. A materialization graph $\mathcal{G}$
is being constructed for some datalog program $\langle R, \textbf{I}\rangle$.
The nodes in the dashed box denote the ones that have been added to $\mathcal{G}$.
In this snapshot, $v_0$ has been newly added
to $\mathcal{G}$ in the $l^{th}$ ($l\geq 1$) iteration.
Each of the nodes $v_i$ ($1\leq i\leq k$) has almost one parent node being not in $\mathcal{G}$,
while $v'$ has two parent nodes being not in $\mathcal{G}$.
All of the nodes $v_i$ ($1\leq i\leq k$) and $v'$ would be added to $\mathcal{G}$
afterwards.
\end{example}


In Example~\ref{exp:general}, $v_k$ would be added to $\mathcal{G}$ after \emph{at least} $k$
iterations by performing Algorithm~$\mathsf{A}_{bsc}$.
We can check that each edge $(v_{i-1},v_i)$ ($1\leq i\leq k$) in this stage follows the condition:
\emph{if the parent node $v_{i-1}$ is derivable, the child node $v_i$ has to be derivable} (this
is because that, for node $v_i$, node $v_{i-1}$ is the only parent node that has not been added to $\mathcal{G}$).
We call this condition \emph{the single-way derivability condition}, which intuitively says that the derivability of a
node only depends on one of its parent nodes.
Observe that node $v_k$ is reachable from node $v_0$ through the path $\tau=(v_0,v_1,...,v_k)$ where
each edge $(v_{i-1},v_i)$ ($1\leq i\leq k$) follows the single-way derivability condition;
we call such a path a \emph{single-way derivable} (SWD) path.
Further, the starting node $v_0$ in $\tau$ has been added to $\mathcal{G}$; in other words,
$v_0$ is derivable. Thus, all of the nodes $v_i$ ($1\leq i\leq k$) can be added to
$\mathcal{G}$ immediately.
Based on the above idea, we optimize Algorithm~$\mathsf{A}_{bsc}$ by checking whether such an SWD path
exits for some node $v$; if there is an SWD path for node $v$, this node can be added to $\mathcal{G}$
due to the single-way derivability condition.

Backing to Example~\ref{exp:general}, since
there exists an SWD path $(v_0,...,v_i)$ for each node $v_i$ ($1\leq i\leq k$), all of these nodes
can be added to $\mathcal{G}$ right after $v_0$. On the other hand,
node $v'$ has no SWD path, since it has two parent nodes being not in $\mathcal{G}$.

We next discuss how to determine the existence of SWD paths. Note that, SWD paths require us to
describe the reachability between two nodes. To this extent, we use a
binary transitive relation $\texttt{rch} \subseteq T_R^{\omega}(\textbf{I})\times T_R^{\omega}(\textbf{I})$,
e.g., \texttt{rch}$(v_1,v_2)$ means that $v_2$ is reachable from $v_1$.
In each iteration of \ref{alg1:updateG} in Algorithm~$\mathsf{A}_{bsc}$, we further compute a \texttt{rch}
relation (denoted by $S_{\textit{\tiny rch}}$) by performing the following process:

\begin{description}[leftmargin=2ex]
\item[(\textbf{\dag})] \emph{For each rule instantiation of the form $B_1,..,B_i,..,B_n\rightarrow H$
where $H$ has been added to $\mathcal{G}$}:
\begin{enumerate}[leftmargin=2ex]
\item \emph{if the body atoms $B_1,...,B_n$ have all been added to $\mathcal{G}$, put \texttt{rch}$(B_1,H),...,$ \texttt{rch}$(B_n,H)$ in $S_{\textit{\tiny rch}}$};
\item \emph{if $B_i$ is the only node in the body that has not been added to $\mathcal{G}$,
    put \texttt{rch}$(B_i,H)$ in $S_{\textit{\tiny rch}}$}.\hfill$\Box$
\end{enumerate}
\end{description}

We then compute the transitive closure (denoted by $S^*_{\textit{\tiny rch}}$) with respect to
$S_{\textit{\tiny rch}}$. Based on the transitive closure, we can perform the optimization that,
for a node $v$, if there is a relation $\texttt{rch}(v',v)\in S^*_{\textit{\tiny rch}}$
where $v'$ has been added to $\mathcal{G}$, $v$ has an SWD path and can be added to $\mathcal{G}$.
The following algorithm applies this optimization strategy.\\

\noindent\texttt{Algorithm~$\mathsf{OPT}$}. The algorithm requires two inputs:
a datalog program $P=\langle R, \textbf{I}\rangle$ and a (partial) materialization graph $\mathcal{G}$ that is
being constructed from $P$. The following steps are performed:
\begin{enumerate}[leftmargin=6ex,label=(\textbf{\roman*})]
\item Compute a \texttt{rch} relation $S_{\textit{\tiny rch}}$ by following the above process (see $(\textbf{\dag})$).\label{rch}
\item Compute the transitive closure $S^*_{\textit{\tiny rch}}$ of $S_{\textit{\tiny rch}}$.\label{transClos}
\item Update $\mathcal{G}$ as follows: for any \texttt{rch}$(B_i,H)\in S_{\textit{\tiny rch}}$
that corresponds to `$B_1,..,B_i,..$ $,B_n\rightarrow H$'
    and there exists a node $B'$ such that \texttt{rch}$(B',B_i)\in S^*_{\textit{\tiny rch}}$ and $B'$ is
    in $\mathcal{G}$; if $H$ is not in $\mathcal{G}$ or $H$ is in $\mathcal{G}$ but has no parent pointing
    to it, add $H$ and $B_i$ (if $B_i$ is not in $\mathcal{G}$) to $\mathcal{G}$, and create the edges
    $e(B_1, H),...,e(B_n, H)$ in $\mathcal{G}$. Do nothing for other statements
    \texttt{rch}$(B_j,H)\in S_{\textit{\tiny rch}}$.\label{updateG}\hfill$\Box$
\end{enumerate}

It is well known that there is an \texttt{NC} algorithm for computing the
transitive closure \cite{Allender07}.
Based on this result and Algorithm~$\mathsf{OPT}$, we propose an optimized variant of Algorithm~$\mathsf{A}_{bsc}$:\\

\noindent\texttt{Algorithm~$\mathsf{A}_{opt}$}. Given a datalog program $P=\langle R, \textbf{I}\rangle$, the algorithm
returns a materialization graph $\mathcal{G}$ of $P$. Initially $\mathcal{G}$ is empty. The following steps are then performed:
\begin{enumerate}[leftmargin=8ex,label=(\textit{Step \arabic*}),ref=Step~\arabic*]
\item Add all facts in $\textbf{I}$ to $\mathcal{G}$.\label{alg3:addFacts}
\item Compute $S_{\textit{\tiny rch}}$ by performing \ref{rch} in Algorithm~$\mathsf{OPT}$; use an \texttt{NC}
    algorithm to compute the transitive closure $S^*_{\textit{\tiny rch}}$ (see \ref{transClos} in Algorithm~$\mathsf{OPT}$);
    update $\mathcal{G}$ by performing \ref{updateG}  in Algorithm~$\mathsf{OPT}$.\label{alg3:updateG}
\item If no node has been added to $\mathcal{G}$ (in \ref{alg3:updateG}), terminate,
    otherwise iterate \ref{alg3:updateG}. \label{alg3:halt}\hfill$\Box$
\end{enumerate}

It should be noted that there has to be an SWD path for any derivable node in some iteration when performing
Algorithm~$\mathsf{A}_{opt}$.
The following lemma shows the correctness of Algorithm~$\mathsf{A}_{opt}$.

\begin{lemma}\label{lemma:a3}
Given a datalog program $P=\langle R, \textbf{I}\rangle$,
$\mathsf{A}_{opt}$ halts and outputs a materialization graph $\mathcal{G}$ of $P$.
\end{lemma}

\begin{example}\label{exp:opt}
We perform Algorithm~$\mathsf{A}_{opt}$ on the datalog program $P_{ex_1}$ in Example~\ref{exp:mg}.
Initially, $R(a_1,b)$ is in the materialization graph $\mathcal{G}_{ex_1}$.
In the first iteration of \ref{alg3:updateG}, all the rule instantiations are in two kinds of forms:
`$R(a_i,b),A(b)\rightarrow A(a_i)$' and `$S(a_i,a_{i-1}),$ $R(a_{i-1},b)\rightarrow R(a_i,b)$' $(2\leq i\leq k)$,
$S_{\textit{\tiny rch}}$ is the set $\{$\texttt{rch}$(R(a_{i-1},b), R(a_i,b))|2\leq i\leq k\}
\cup\{$\texttt{rch}$(R(a_i,b), A(a_i))|1\leq i\leq k\}$.
In the transitive closure of $S_{\textit{\tiny rch}}$,
one can check that \texttt{rch}$(R(a_1,b), R(a_i,b)),$
\texttt{rch}$(R(a_1,b), A(a_i))\in S^*_{\textit{\tiny rch}}(2\leq i\leq k)$.
Thus, $R(a_i,b)$ and $A(a_i)$ ($2\leq i\leq k$) can all be added to $\mathcal{G}_{ex_1}$
in the first iteration of \ref{alg3:updateG}.
\end{example}

We obtain an \texttt{NC} variant of $\mathsf{A}_{opt}$ analogously to the process for Algorithm~$\mathsf{A}_{bsc}$.
It can be checked that an iteration of \ref{alg3:updateG} in $\mathsf{A}_{opt}$ costs poly-logarithmic
time, since the main part is computing $S^*_{\textit{\tiny rch}}$ by an \texttt{NC} algorithm.
Thus, if the number of iterations of \ref{alg3:updateG} is upper-bounded by a poly-logarithmical function,
$\mathsf{A}_{opt}$ is an \texttt{NC} algorithm.
Analogously to $\mathsf{A}_{bsc}^{\psi}$, we use $\mathsf{A}_{opt}^{\psi}$ to denote an \texttt{NC} variant.
Specifically, for any datalog program $P$, the number of iterations of \ref{alg3:updateG} in $\mathsf{A}_{opt}$
is bounded by $\psi(|P|)$, where $\psi$ is a poly-logarithmically bounded function.

Based on $\mathsf{A}_{opt}^{\psi}$, we can identify a \texttt{PTD} class $\mathcal{D}_{\mathsf{A}_{opt}^{\psi}}$.
Further, we have the following corollary which implies that $\mathsf{A}_{opt}^{\psi}$ performs better
than $\mathsf{A}_{bsc}^{\psi}$ in terms of computing time.

\begin{corollary}
For any poly-logarithmically bounded function $\psi$,
we have that $\mathcal{D}_{\mathsf{A}_{bsc}^{\psi}}\subseteq\mathcal{D}_{\mathsf{A}_{opt}^{\psi}}$.
\end{corollary}

\begin{proof}[Proof sketch]
Suppose $P\in\mathcal{D}_{\mathsf{A}_{bsc}^{\psi}}$. According to Theorem~\ref{theorem:a1},
the depth of the materialization graph $\mathcal{G}$ constructed by $\mathsf{A}_{bsc}^{\psi}$ is upper-bounded by $\psi(|P|)$.
It is obvious that the number of nodes in each path of $\mathcal{G}$ is also upper-bounded by $\psi(|P|)$.
According to the optimization strategy applied in $\mathsf{A}_{opt}$, if $\mathcal{G}$ can be constructed
by $\mathsf{A}_{opt}$, the number of iterations of $\mathsf{A}_{opt}$ has to be upper-bounded by $\psi(|P|)$;
if $\mathcal{G}$ is not the materialization graph constructed
by $\mathsf{A}_{opt}$, then there has to exist another materialization graph $\mathcal{G}'$ constructed by $\mathsf{A}_{opt}$
and $\mathcal{G}'$ has a smaller depth compared with $\mathcal{G}$.
\end{proof}


\section{Parallel Tractability of Ontology Materialization in OWL}
\label{sec:ptonto}

In this section, we study the issue of parallel tractability
for materialization of DL-Lite and DHL (DHL($\circ$)) ontologies
based on Algorithm~$\mathsf{A}_{opt}$.
We show that, for any DL-Lite$_{core}$ or DL-Lite$_\mathcal{R}$ ontology $\mathcal{O}$,
there exists a poly-logarithmically bounded function $\psi$
such that Algorithm~$\mathsf{A}_{opt}^{\psi}$ can handle materialization of $\mathcal{O}$.
However, for DHL and DHL($\circ$), there exist ontologies such that Algorithm~$\mathsf{A}_{opt}^\psi$
does not work. We illustrate the reason why Algorithm~$\mathsf{A}_{opt}^\psi$ cannot always
work by studying specific cases.
Further, we propose to restrict the usage of DHL and DHL($\circ$) in order to achieve parallel tractability
of materialization.

\subsection{Materialization of DL-Lite Ontologies via Algorithm~$\mathsf{A}_{opt}$}

In this part, we show how to use Algorithm~$\mathsf{A}_{opt}$ to handle
DL-Lite materialization and analyze its parallel tractability.
Based on the analysis, we have that, for any DL-Lite$_{core}$ or DL-Lite$_\mathcal{R}$ ontology
there always exists an SWD path for each atom of the form $A(a)$ or $R(a,b)$.
In other words, all atoms of the forms $A(a)$ and $R(a,b)$ can be added to
the constructed materialization graph in the first iteration of \ref{alg3:updateG}
by performing Algorithm~$\mathsf{A}_{opt}$.

In order to show how Algorithm~$\mathsf{A}_{opt}$ handles DL-Lite materialization,
we use the following example.

\begin{example}\label{exp:dllite}
Given a DL-Lite ontology $\mathcal{O}_{ex_2}$
where its TBox and RBox contain the following axioms:
$A\sqsubseteq B_1$, $A\sqsubseteq B_2$, $B_1\sqcap B_2\sqsubseteq\bot$,
$\exists R.B_2\sqsubseteq\bot$, $Q\sqsubseteq S^-$, $S\sqsubseteq R$;
its ABox contains an assertion $Q(a,b)$.
We denote the corresponding datalog program of $\mathcal{O}_{ex_2}$ by $P_{ex_2}=\langle R, \textbf{I}\rangle$,
where $R$ contains the rules that are transformed from the above axioms; $\textbf{I}$ contains $Q(a,b)$
as the only fact.
The unique materialization graph of $P_{ex_2}$ is denoted by $\mathcal{G}_{ex_2}$ (see Figure~\ref{fig:ex2}).
\end{example}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\textwidth]{fig-dllite.eps}
\caption{The materialization graph of $\mathcal{O}_{ex_2}$.}
\label{fig:ex2}
\end{center}
\end{figure}

Consider performing Algorithm~$\mathsf{A}_{opt}$ on the ontology $\mathcal{O}_{ex_2}$ in Example~\ref{exp:dllite}.
(\uppercase\expandafter{\romannumeral1}) First, Algorithm~$\mathsf{A}_{opt}$ adds all ABox assertions (only $Q(a,b)$ here)
to $\mathcal{G}_{ex_2}$ that is initially an empty graph (\ref{alg3:addFacts} of Algorithm~$\mathsf{A}_{opt}$).
(\uppercase\expandafter{\romannumeral2}) In the first iteration of
\ref{alg3:updateG}, Algorithm~$\mathsf{A}_{opt}$ checks that all of the nodes
$A(a)$, $S(b,a)$, $B_1(a)$, $B_2(a)$ and $R(b,a)$ have corresponding SWD paths
starting from $Q(a,b)$. Thus, Algorithm~$\mathsf{A}_{opt}$
adds these nodes to $\mathcal{G}_{ex_2}$ immediately. We take an example of node $B_1(a)$,
for which an SWD path $(Q(a,b),A(a),B_1(a))$ exists.
When updating $\mathcal{G}_{ex_2}$ by adding $B_1(a)$ to it,
Algorithm~$\mathsf{A}_{opt}$ first checks whether the parent node $A(a)$ of $B_1(a)$
has been in $\mathcal{G}_{ex_2}$; if $A(a)$ is already in $\mathcal{G}_{ex_2}$, $B_1(a)$
is added to $\mathcal{G}_{ex_2}$ by creating an edge pointing from $A(a)$ to $B_1(a)$;
if $A(a)$ has not been added to $\mathcal{G}_{ex_2}$, Algorithm~$\mathsf{A}_{opt}$ adds $A(a)$ (resp., $B_1(a)$)
to $\mathcal{G}_{ex_2}$ and creates an edge pointing from $Q(a,b)$ to $A(a)$ (resp.,
an edge pointing from $A(a)$ to $B_1(a)$).\footnote{These two cases may happen simultaneously,
since node $A(a)$ and node $B_1(a)$ are being processed in parallel.} The other nodes
$A(a)$, $S(b,a)$, $B_2(a)$ and $R(b,a)$ are processed similarly.
(\uppercase\expandafter{\romannumeral3})
The two nodes $\bot(a)$ and $\bot(b)$
have no SWD path in the first iteration of \ref{alg3:updateG}.
They are left to be processed in the second iteration.
(\uppercase\expandafter{\romannumeral4})
Finally, Algorithm~$\mathsf{A}_{opt}$ finishes constructing $\mathcal{G}_{ex_2}$
after two iterations (\ref{alg3:halt}).

From the above example, we can observe that SWD paths exist
for all nodes except $\bot(a)$ and $\bot(b)$ in the first iteration of Algorithm~$\mathsf{A}_{opt}$.
Further, we give the following lemma that satisfies any DL-Lite$_{core}$ or DL-Lite$_\mathcal{R}$ ontology.

\begin{lemma}\label{lemma:dllite}
For any DL-Lite$_{core}$ or DL-Lite$_\mathcal{R}$ ontology $\mathcal{O}$, there exists a materialization graph $\mathcal{G}$ such that
each atom of the form $A(x)$ ($A\neq\bot$) or $R(x,y)$ in $\mathcal{G}$ has an SWD path.
\end{lemma}

The above lemma guarantees that all atoms of the form $A(x)$ ($A\neq\bot$) or $R(x,y)$
have to be added to the constructed materialization graph in the first iteration of
\ref{alg3:updateG} by applying Algorithm~$\mathsf{A}_{opt}$.
For each atom of the form $\bot(x)$, there may not exist an SWD path in the first iteration
of \ref{alg3:updateG}, since its derivability depends on its two parent nodes
(see nodes $\bot(a)$ and $\bot(b)$ in $\mathcal{G}_{ex_2}$ of
Example~\ref{exp:dllite}). On the other hand, according to the syntaxes of DL-Lite,
$\bot$ dose not occur on the left hand of any axiom. In other words,
an atom of the form $\bot(x)$ cannot be the parent of any other node.
This allows all atoms of the form $\bot(x)$ being added
to the constructed materialization graph in at most two iterations of
\ref{alg3:updateG} by applying Algorithm~$\mathsf{A}_{opt}$.
Based on the above discussion, for any DL-Lite ontology $\mathcal{O}$,
there always exists a poly-logarithmically bounded function $\psi$ such that
Algorithm~$\mathsf{A}_{opt}^{\psi}$ can handle the materialization of $\mathcal{O}$;
more precisely, we can set that $\psi=2$. This result is consistent with
that in \cite{CalvaneseGLLR07}.
Formally, we use $\mathcal{D}_{\textit{\text{dl\_lite}}}$
to denote the set of all DL-Lite$_{core}$ and DL-Lite$_\mathcal{R}$ ontologies, and give the following theorem.

\begin{theorem}\label{theorem:dl-lite}
There exists a poly-logarithmically bounded function $\psi$ s.t.
$\mathcal{D}_{\textit{\text{dl\_lite}}}\subseteq\mathcal{D}_{\mathsf{A}_{opt}^{\psi}}$.
\end{theorem}

\subsection{Parallelly Tractable Materialization of DHL}

In this part, we study whether Algorithm~$\mathsf{A}_{opt}^\psi$ can handle DHL ontologies.
Unfortunately there exist DHL ontologies such that Algorithm~$\mathsf{A}_{opt}^\psi$
does not work for any poly-logarithmically bounded function $\psi$.
In the following, we first give such an ontology
to illustrate the reason why Algorithm~$\mathsf{A}_{opt}^\psi$ cannot work.
Based on the analysis of this case, we propose to restrict
the usage of DHL in order to achieve parallel tractability
of materialization.

We find that, an unlimited usage of axioms of the
form $B_1\sqcap B_2\sqsubseteq A$
may make it impossible for Algorithm~$\mathsf{A}_{opt}$ to construct a materialization graph
in a poly-logarithmical number of iterations of \ref{alg3:updateG}.
We use the following example to illustrate it.

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.9\textwidth]{fig-pathtwist.eps}
\caption{(left) The materialization graph of $\mathcal{O}_{ex_3}$;
(right) The materialization graph of $\mathcal{O}_{ex_4}$.}
\label{fig:ex3_4}
\end{center}
\end{figure}

\begin{example}\label{exp:dhl}
Given a DHL ontology $\mathcal{O}_{ex_3}$ where its TBox contains three axioms:
$B_1\sqcap B_2\sqsubseteq A$, $\exists S.A\sqsubseteq B_1$ and $\exists R.A\sqsubseteq B_2$;
the ABox is $\{S(a_i,a_{i-1}), R(a_i,a_{i-1}), A(a_1)\}$
for $2\leq i\leq k$ and $k$ is an integer greater than 2.
We denote the corresponding datalog program of $\mathcal{O}_{ex_3}$ by $P_{ex_3}=\langle R, \textbf{I}\rangle$,
where $R$ contains three rules: `$B_1(x),B_2(x)\rightarrow A(x)$',`$S(x,y),A(y)\rightarrow B_1(x)$' and `$R(x,y),A(y)\rightarrow B_2(x)$'.
The materialization graph of $P_{ex_3}$ constructed by $\mathsf{A}_{opt}$ is denoted by $\mathcal{G}_{ex_3}$ (see Figure~\ref{fig:ex3_4}(left)).
\end{example}

One can check that $\mathcal{G}_{ex_3}$ is the unique materialization graph of $P_{ex_3}$.
Observe that there exists a path (e.g., $A(a_1),B_1(a_2),A(a_2),...,A(a_k)$) between $A(a_1)$ and $A(a_k)$.
When performing Algorithm~$\mathsf{A}_{opt}$ on $P_{ex_3}$, it can be checked that
each node of the form $A(a_i)$ (filled with black color,
and $2\leq i\leq k$) has no SWD path until the $i^{th}$ iteration;
in the $i^{th}$ iteration, the parent nodes of $A(a_i)$ have been added to $\mathcal{G}_{ex_2}$,
and, $A(a_i)$ can also be added to $\mathcal{G}_{ex_2}$.
Thus, Algorithm~$\mathsf{A}_{opt}$ cannot handle $P_{ex_3}$ in a poly-logarithmical
number of iterations.
The intuitive reason is that, at least two paths exist
starting from $A(a_1)$ to $A(a_k)$. These paths \emph{twist} mutually and share the same joint nodes (see the black nodes).
It makes the optimization of acceleration used in Algorithm~$\mathsf{A}_{opt}$ invalid.
That is, for each node $A(a_i)$ ($2\leq i\leq k$), until its parents ($B_1(a_i)$ and $B_2(a_i)$) are added
to $\mathcal{G}_{ex_2}$, there would not exist an available SWD path for $A(a_i)$.
We use `\emph{path twisting}' to represent such cases.

In order to make Algorithm~$\mathsf{A}_{opt}$ terminate in a poly-logarithmical number of iterations,
we consider restricting the usage of axioms of the form $B_1\sqcap B_2\sqsubseteq A$
to avoid `path twisting'. An intuitive idea is to
ensure that \emph{there is only one path between each two atoms of the form $A(x)$
generated from the rules corresponding to (T1)}.
We explain it by using the following example where the ontology is modified from
that in Example~\ref{exp:dhl}.

\begin{example}\label{exp:simpleC}
Consider an ontology where the TBox contains three axioms:
$B_1\sqcap B_2\sqsubseteq A$, $\exists S.A\sqsubseteq B_1$ and $B_3\sqsubseteq B_2$;
the ABox is $\{S(a_i,a_{i-1}), B_3(a_i), A(a_1)\}$
for $2\leq i\leq k$ and $k$ is an integer greater than 2.
We denote the corresponding datalog program by $P_{ex_4}$ where the rule set contains:
`$B_1(x),B_2(x)\rightarrow A(x)$',`$S(x,y),A(y)\rightarrow B_1(x)$' and `$B_3(x)\rightarrow B_2(x)$'.
$P_{ex_3}$ has a unique materialization graph denoted by $\mathcal{G}_{ex_4}$ (see Figure~\ref{fig:ex3_4}(right)).
\end{example}

In the above example, for the axiom $B_1\sqcap B_2\sqsubseteq A$, all derived atoms
of the form $B_2(x)$ must not be child nodes of an atom $A(y)$ for some $y$.
This ensures that only one path exists between each two nodes among $A(a_2),...,A(a_k)$.
Further, when constructing $\mathcal{G}_{ex_4}$, Algorithm~$\mathsf{A}_{opt}$ can terminate after
two iterations of \ref{alg3:updateG}. Specifically, in the first iteration, Algorithm~$\mathsf{A}_{opt}$
adds all of the nodes $B_3(a_i)$ and $B_2(a_i)$ ($2\leq i\leq k$) to $\mathcal{G}_{ex_4}$,
since they have corresponding SWD paths;
after that, all the other nodes
can be added to $\mathcal{G}_{ex_4}$ in the second iteration (because each
node has an SWD path).
Motivated by this example, we consider restricting the usage of
the axioms $B_1\sqcap B_2\sqsubseteq A$
such that all atoms of the form $B_1(x)$ or $B_2(x)$ cannot be generated by an atom $A(y)$
for some $y$.
To this end, we first define \emph{simple concepts} as follows:

\begin{definition}
Given an ontology $\mathcal{O}=\langle\mathcal{T},\mathcal{R},\mathcal{A}\rangle$,
a concept $A\in\textbf{CN}$ is simple, if (1) $A$ does not occur on the right-hand side
of some axiom; or (2) $A$ satisfies the following conditions:
\begin{enumerate}[leftmargin=4ex,label=\arabic*.]
\item for each $B\sqsubseteq A\in\mathcal{T}$, $B$ is simple;
\item for each $\exists R.B\sqsubseteq A\in\mathcal{T}$, $B$ is simple;
\item there is no axiom of the form $B_1\sqcap B_2\sqsubseteq A$ in $\mathcal{T}$.
\end{enumerate}
\end{definition}

Based on simple concepts, we restrict DHL ontologies such that, in all axioms of the
form $B_1\sqcap B_2\sqsubseteq A$, at least one concept of $B_1$ and $B_2$ should be a simple concept
(we call it \emph{simple-concept restriction}).
Intuitively, for the restricted DHL ontologies, the situation of `path twisting' would not happen.
This is because, if in each axiom of the form $B_1\sqcap B_2\sqsubseteq A$, w.l.o.g., $B_1$
is a simple concept, then none of ancestors of $B_1(x)$ for some $x$
is generated from the rules corresponding to (T1).

\begin{example}
In the ontology of Example~\ref{exp:dhl}, all of $A$, $B_1$ and $B_2$ are
non-simple concepts.
In the ontology of Example~\ref{exp:simpleC}, $A$ and $B_1$ are non-simple concepts,
while $B_3$ and $B_2$ are simple concepts. Further, it can be checked that,
the ontology  of Example~\ref{exp:simpleC} follows the simple-concept restriction
and can be handled by Algorithm~$\mathsf{A}_{opt}^\psi$ for some poly-logarithmical function $\psi$.
\end{example}

We define the following class of DHL ontologies based on the above restriction and
give Theorem \ref{theorem:dhl} to show that any DHL ontology that satisfies the
simple-concept restriction can be handled by Algorithm~$\mathsf{A}^\psi_{opt}$
for some poly-logarithmical function $\psi$.

\begin{definition} Let $\mathcal{D}_{\textit{\text{dhl}}}$ be a class of datalog programs where
each program is rewritten from a DHL ontology that follows the condition that, for all axioms of the form
$A_1\sqcap A_2\sqsubseteq B$, at least one concept of $A_1$ and $A_2$ should be a \emph{simple concept}.
\end{definition}

\begin{theorem}\label{theorem:dhl}
There exists a poly-logarithmically bounded function $\psi$ s.t.
$\mathcal{D}_{\textit{\text{dhl}}}\subseteq\mathcal{D}_{\mathsf{A}_{opt}^{\psi}}$.
\end{theorem}


\subsection{Parallelly Tractable Materialization of DHL($\circ$)}

In this part, we study parallelly tractable materialization
of DHL($\circ$) ontologies.
In addition to the rules in DHL, we also have to consider complex RIAs (R4).
We next show that complex RIAs may also cause the situation of `path twisting'.
Consider the following example.

\begin{example}\label{exp:complexRIA}
Given a DHL$(\circ)$ ontology $\mathcal{O}_{ex_5}$ where its TBox is empty;
the RBox $\mathcal{R}$ contains three axioms:
$R_1\circ R_2\sqsubseteq R$, $R_3\circ R\sqsubseteq R_1$ and $R\circ R_4\sqsubseteq R_2$;
the ABox $\mathcal{A}$ is $\{R(a_1,a_1), R_3(a_i,a_{i-1}), R_4(a_{i-1},a_i)\}$
for $2\leq i\leq k$ and $k$ is an integer greater than 2.
The corresponding datalog program $P_{ex_5}$
contains three rules: `$R_1(x,y),R_2(y,z)\rightarrow R(x,z)$',
`$R_3(x,y),R(y,z)\rightarrow R_1(x,z)$' and `$R(x,y),R_4(y,z)\rightarrow R_2(x,z)$'.
The materialization graph of $P_{ex_5}$ constructed by Algorithm~$\mathsf{A}_{opt}$ is denoted by $\mathcal{G}_{ex_5}$.
\end{example}

One can check that the materialization graph $\mathcal{G}_{ex_5}$ has the same shape as that
of $\mathcal{G}_{ex_3}$ in Figure~\ref{fig:ex3_4}.
A twisted path exists in $\mathcal{G}_{ex_5}$ involving $R(a_i,a_i) (2\leq i\leq k)$ as the joint nodes.
Further, all the roles $R_1$, $R_2$, $R_3$, $R_4$ and $R$ in this example are non-transitive roles.

Inspired by what we do for axioms $B_1\sqcap B_2\sqsubseteq A$,
we require that, for all axioms of the form $R_1\circ R_2\sqsubseteq R$,
if $R$ is not a transitive role and no transitive role $S$ exists such that $R\sqsubseteq_* S$,
then, at least one of $R_1$ and $R_2$ is
a \emph{simple role}.\footnote{See the definition of a simple role in Section~\ref{sec:background}.}
We now consider such an axiom $R_1\circ R_2\sqsubseteq R$ (denoted by $\alpha_1$) where $R$ is a transitive role.
That is we also have $R\circ R\sqsubseteq R$ (denoted by $\alpha_2$).
By replacing $R$ on the left-hand of $\alpha_2$ using $R_1$ and $R_2$,
we can get a complex RIA in the form of
$R_1\circ R_2\circ R_1\circ R_2\sqsubseteq R$ (denoted by $\alpha_3$).
If one of $R_1$ and $R_2$ is not a simple role, the corresponding
rule of $\alpha_3$ may also lead to `path twisting'.\footnote{Obviously, applying the rules of $\alpha_1$
and $\alpha_2$ separately has the same effect to that of only applying the rule of $\alpha_3$.}
The reason can be explained as follows.
Without loss of the generality,
$R_2$ is a simple role while $R_1$ is not.
For some atom $R(x,y)$, it may depend on two different nodes of the predicate $R_1$
through the corresponding rule of $\alpha_3$. The similar analysis applies to
such cases of $\alpha_1$ where $R$ is not a transitive role, while another transitive
role $S$ exists such that $R\sqsubseteq_* S$. That is, we can obtain
a complex RIA of the form $R_1\circ R_2\circ R_1\circ R_2\sqsubseteq S$.
Further, the situation of path twisting also exists.
To tackle the above issue,
we require both of $R_1$ and $R_2$ in $\alpha_1$ to be simple roles
(we call the above restriction for transitive and non-transitive roles \emph{simple-role restriction}).
Combined with the simple-concept restriction,
we define a class of DHL($\circ$) ontologies as follows:

\begin{definition}\label{def:dhlplus}
$\mathcal{D}_{\textit{\text{dhl}}(\circ)}$ is a class of datalog programs where each program
is rewritten from a DHL($\circ$) ontology and the following
conditions are satisfied:
\begin{enumerate}[leftmargin=4ex,label=\arabic*.]
\item for all axioms of the form $A_1\sqcap A_2\sqsubseteq B$,
    at least one concept of $A_1$ and $A_2$ should be a \emph{simple concept};
\item for all axioms of the form $R_1\circ R_2\sqsubseteq R$,
    if there does not exits a transitive role $S$ such that $R\sqsubseteq_* S$, then,
    at least one of $R_1$ and $R_2$ is a \emph{simple role}; otherwise, both of $R_1$ and $R_2$ are \emph{simple roles}.
\end{enumerate}
\end{definition}

\begin{example}
For the ontology $\mathcal{O}_{ex_4}$ in Example~\ref{exp:complexRIA}, all of the roles
$R_1$, $R_2$ and $R$ are non-simple roles. Thus, $\mathcal{O}_{ex_4}$ does not follow
the simple-role restriction because of $R_1\circ R_2\sqsubseteq R$.
Consider the ontology $\mathcal{O}_{ex_1}$
in Example~\ref{exp:mg} again. The role $R$ is a non-simple role, while $S$ is a simple role.
Thus $\mathcal{O}_{ex_1}$ follows the simple-role restriction. All the implicit nodes
in $\mathcal{G}_{ex_1}$ have corresponding SWD paths in the first iteration.
Thus, `path twisting' cannot occur when materializing $\mathcal{O}_{ex_1}$ by Algorithm~$\mathsf{A}_{opt}$.
\end{example}

We further give Theorem~\ref{theorem:dhlplus} to show that Algorithm~$\mathsf{A}_{opt}^{\psi}$ can handle
all the datalog programs in $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$ for some poly-logarithmical function $\psi$.

\begin{theorem}\label{theorem:dhlplus}
There exists a poly-logarithmically bounded function $\psi$ s.t. $\mathcal{D}_{\textit{\text{dhl}}(\circ)}\subseteq\mathcal{D}_{\mathsf{A}_{opt}^{\psi}}$.
\end{theorem}


\section{A Further Optimized Algorithm for DHL$(\circ)$ Materialization}
\label{sec:practicalAlg}

In this section, we first discuss that Algorithm~$\mathsf{A}_{opt}$ can hardly work in practice.
In order to make Algorithm~$\mathsf{A}_{opt}$ more practical,
we propose to modify Algorithm~$\mathsf{A}_{opt}$ and give an algorithm variant Algorithm~$\mathsf{A}_{prc}$.
We show that Algorithm~$\mathsf{A}_{prc}$ can also be restricted to an $\texttt{NC}$ version
when materializing DHL$(\circ)$ ontologies that follow both of the simple-concept
and the role-concept restrictions.

\subsection{Reducing Computing Space}

In previous sections, Algorithm~$\mathsf{A}_{opt}$ is mainly used for theoretical analysis.
However, this algorithm can hardly work in practice due to its inherently
high requirement of computing space. Specifically,
Algorithm~$\mathsf{A}_{opt}$ constructs a materialization graph by checking all possible rule
instantiations in $P^*$ where $P$ is a datalog program that corresponds to an ontology.
One can check that $|P^*|$ could be the square or cube of the number of constants occurring in $P$.
Consider a datalog rule of the form `$R(x,y),A(y)\rightarrow B(x)$'
that is rewritten from the axiom of the form $\exists R.A\sqsubseteq B$;
since there are two variables in this rule, the number of all possible rule instantiations
is $|\textbf{IN}|^2$; if there are
1000 individuals in \textbf{IN}, this number is 1 million.
Similarly, for a datalog rule rewritten from an axiom of the form (R3) or (R4),
the number of all possible rule instantiations is $|\textbf{IN}|^3$.
It is no doubt that a plain implementation of Algorithm~$\mathsf{A}_{opt}$ would be delayed
when the target datalog program or ontology
tends to be large in size.
On the other hand, from Examples~\ref{exp:mg}, \ref{exp:dllite} and \ref{exp:dhl},
we can observe that the rule instantiations used for the construction
of materialization graphs always cover a small part of $P^*$ with respect to the target datalog program $P$.
Thus, we consider reducing the computing space of Algorithm~$\mathsf{A}_{opt}$
by narrowing down the scope of rule instantiations to be checked.
Our strategy is to restrict that, \emph{in each iteration of Algorithm~$\mathsf{A}_{opt}$,
each of the checked rule instantiations should involve at least one body atom that has been
added to the constructed materialization graph}.
Since DHL$(\circ)$
is our focus, we explain how to apply the above strategy in DHL$(\circ)$ materialization
as follows.

We first consider a datalog rule of the
form `$A(x)\rightarrow B(x)$' that corresponds to (T1). The above strategy requires that,
in each iteration, Algorithm~$\mathsf{A}_{opt}$ can only check the rule instantiations
of the form `$A(a)\rightarrow B(a)$' where $A(a)$ has been added to the constructed materialization
graph $\mathcal{G}$. If there are $n$ atoms of the form $A(x)$ that have been added to $\mathcal{G}$,
the number of all checked rule instantiations of the above rule is also $n$, instead of $|\textbf{IN}|$.
This is because that, for each assertion $A(a)$,
the datalog rule `$A(x)\rightarrow B(x)$'
has only one rule instantiation `$A(a)\rightarrow B(a)$' where
the variable $x$ is substituted by the constant $a$.
The cases of (R1) and (R2) can be analyzed similarly.
We now consider the datalog rules that have two body atoms, i.e.,
the datalog rules of the forms `$R(x,y),A(y)\rightarrow B(x)$' (see (T3)),
`$A_1(x),A_2(x)\rightarrow B(x)$' (see (T2)) and `$R_1(x,y),R_2(y,z)\rightarrow R(x,z)$' (see (R3) and (R4)).
We require that, for each rule instantiation of these rules checked by Algorithm~$\mathsf{A}_{opt}$,
at least one body atom has been added to the constructed materialization
graph $\mathcal{G}$; thus, it can be checked that, in each iteration of Algorithm~$\mathsf{A}_{opt}$,
the number of checked rule instantiations
is at most $k|\textbf{IN}|$ where $k$ is the number of atoms that have been
added to $\mathcal{G}$.
Note that, for rule instantiations of two body atoms,
we do not require that both of these two body atoms have been added to
the constructed materialization graph.
Otherwise, the algorithm would
perform as the same as Algorithm~$\mathsf{A}_{bsc}$, and thus, the
optimizations used in Algorithm~$\mathsf{A}_{opt}$ cannot further work.



\subsection{Further Optimizing Algorithm~$\mathsf{A}_{opt}$}


We use the above method of narrowing down the scope of rule instantiations to
modify Algorithm~$\mathsf{A}_{opt}$ and obtain an algorithm variant Algorithm~$\mathsf{A}_{prc}$.
Recall that,
in each iteration of \ref{alg3:updateG}, Algorithm~$\mathsf{A}_{opt}$
checks all possible rule instantiations and computes a \texttt{rch} relation
and its transitive closure to determine the existence of SWD paths.
We let Algorithm~$\mathsf{A}_{prc}$ conduct the same work with
narrowing down the scope of rule instantiations to be checked as well. This can be described
by the following algorithm.\\

\noindent\texttt{Algorithm~$\mathsf{PRC}$}. This algorithm has inputs (1)
a DHL$(\circ)$ ontology $\mathcal{O}=\langle\mathcal{T},\mathcal{R},\mathcal{A}\rangle$
and its datalog program $P=\langle R, \textbf{I}\rangle$;
(2) a (partial) materialization graph $\mathcal{G}$ that is constructed from $P$.
This algorithm outputs a \texttt{rch} relation $S_{\textit{\tiny rch}}$ that
is computed from the following rule instantiations:

\begin{enumerate}[leftmargin=4ex,label=$\bullet$]
\item $\forall A(a)\rightarrow B(a)$ where $\mathcal{O}\models A\sqsubseteq_* B$ and $A(a)\in\mathcal{G}$,
    add \texttt{rch}$(A(a),B(a))$ to $S_{\textit{\tiny rch}}$;

\item $\forall R(a,b),A(b)\rightarrow B(a)$ where $\exists R.A\sqsubseteq B\in\mathcal{T}$
    and $R(a,b)\in\mathcal{G}$, add \texttt{rch}$(A(b),B(a))$ to $S_{\textit{\tiny rch}}$;

\item $\forall A_1(a),A_2(a)\rightarrow B(a)$ where $A_1\sqcap A_2\sqsubseteq B\in\mathcal{T}$,
    if $A_1(a)\in\mathcal{G}$, add \texttt{rch}$(A_2(a),B(a))$ to $S_{\textit{\tiny rch}}$;
    if $A_2(a)\in\mathcal{G}$, add \texttt{rch}$(A_1(a),B(a))$ to $S_{\textit{\tiny rch}}$;

\item $\forall R(a,b)\rightarrow S(a,b)$ where $\mathcal{O}\models R\sqsubseteq_* S$ and $R(a,b)\in\mathcal{G}$,
    add \texttt{rch}$(R(a,b)$, $S(a,b))$ to $S_{\textit{\tiny rch}}$;

\item $\forall R(a,b)\rightarrow S(b,a)$ where $\mathcal{O}\models R\sqsubseteq_* S^-$
    and $R(a,b)\in\mathcal{G}$, add \texttt{rch}$(R(a,b)$, $S(b,a))$ to $S_{\textit{\tiny rch}}$;

\item $\forall R_1(a,b),R_2(b,c)\rightarrow R_3(a,c)$ where $R_1\circ R_2\sqsubseteq R_3$ (the case
    where $R_1\equiv R_2\equiv R_3$ is also involved),
    if $R_1(a,b)\in\mathcal{G}$, add \texttt{rch}$(R_2(b,c),R_3(a,c))$ to $S_{\textit{\tiny rch}}$;
    If $R_2(b,c)\in\mathcal{G}$, add \texttt{rch}$(R_1(a,b)$, $R_3(a,c))$ to $S_{\textit{\tiny rch}}$.\hfill$\Box$
\end{enumerate}

Based on Algorithm~$\mathsf{PRC}$, we modify Algorithm~$\mathsf{A}_{opt}$
by replacing the step \ref{rch} of Algorithm~$\mathsf{OPT}$
to Algorithm~$\mathsf{PRC}$. Algorithm~$\mathsf{A}_{prc}$
is thus given as follows:\\

\noindent\texttt{Algorithm~$\mathsf{A}_{prc}$}. Given
a DHL$(\circ)$ ontology $\mathcal{O}=\langle\mathcal{T},\mathcal{R},\mathcal{A}\rangle$ and its
datalog program $P=\langle R, \textbf{I}\rangle$, this algorithm
returns a materialization graph $\mathcal{G}$ of $P$.
Initially $\mathcal{G}$ is empty. The following steps are then performed:
\begin{enumerate}[leftmargin=8ex,label=(\textit{Step \arabic*}),ref=Step~\arabic*]
\item Add all facts in $\textbf{I}$ to $\mathcal{G}$.\label{alg4:addFacts}
\item Compute $S_{\textit{\tiny rch}}$ by performing Algorithm~$\mathsf{PRC}$; use an \texttt{NC}
    algorithm to compute the transitive closure $S^*_{\textit{\tiny rch}}$ (see \ref{transClos} in Algorithm~$\mathsf{OPT}$);
    update $\mathcal{G}$ by performing \ref{updateG} in Algorithm~$\mathsf{OPT}$.\label{alg4:updateG}
\item If no node has been added to $\mathcal{G}$ (in \ref{alg4:updateG}), terminate,
    otherwise iterate \ref{alg4:updateG}. \label{alg4:halt}\hfill$\Box$
\end{enumerate}

\begin{theorem}\label{theorem:aprc}
For any DHL$(\circ)$ ontology $\mathcal{O}$, Algorithm~$\mathsf{A}_{prc}$ halts and outputs
a materialization graph of $\mathcal{O}$.
\end{theorem}

The above theorem is given to show the correctness of Algorithm~$\mathsf{A}_{prc}$.
We next use an example to show how Algorithm~$\mathsf{A}_{prc}$ handles
DHL$(\circ)$ materialization.

\begin{example}\label{exp:prc}
Consider performing Algorithm~$\mathsf{A}_{prc}$ on the ontology
$\mathcal{O}_{ex_1}$ in Example~\ref{exp:mg}. Note that the individual
set \textbf{IN}$=\{a_1,...,a_k,b\}$ where $k+1$ individuals are involved.
Initially, Algorithm~$\mathsf{A}_{prc}$ adds
all the facts ($A(b),R(a_1,b),S(a_2,a_1),...,S(a_{k},a_{k-1})$) to the
result $\mathcal{G}_{ex_1}$ (\ref{alg4:addFacts}). In the first iteration of
\ref{alg4:updateG}, Algorithm~$\mathsf{A}_{prc}$ computes $S_{\textit{\tiny rch}}$ first.
According to Algorithm~$\mathsf{PRC}$, for each atom of the form $S(a_i,a_{i-1})$ ($2\leq i\leq k$)
and $\forall o\in$\textbf{IN},
an $\texttt{\emph{rch}}$ relation of the form $\texttt{\emph{rch}}(R(a_{i-1},o),R(a_i,o))$ is added to
$S_{\textit{\tiny rch}}$. Since the atom $R(a_1,b)$ has been added to $\mathcal{G}_{ex_1}$,
Algorithm~$\mathsf{A}_{prc}$ checks that all atoms of the form $R(a_i,b)$ ($2\leq i\leq k$)
have SWD paths and are added to $\mathcal{G}_{ex_1}$ in the first iteration.
In the second iteration of \ref{alg4:updateG}, since all atoms of the form $R(a_i,b)$ ($1\leq i\leq k$)
have been in $\mathcal{G}_{ex_1}$, the $\texttt{\emph{rch}}$ relations of the form $\texttt{\emph{rch}}(A(b),A(a_i))$
are checked with respect to the axiom $\exists R.A\sqsubseteq A$; further all
atoms of the form $A(a_i)$ ($1\leq i\leq k$) are finally added to $\mathcal{G}_{ex_1}$
by Algorithm~$\mathsf{A}_{prc}$.
\end{example}

From the above example, one can find that Algorithm~$\mathsf{A}_{prc}$ terminates after two iterations
of \ref{alg4:updateG}. This is the same as Algorithm~$\mathsf{A}_{opt}$ (see Example~\ref{exp:opt}).
We use Theorem~\ref{theorem:aprcpt} to show that Algorithm~$\mathsf{A}_{prc}$ also has an $\texttt{NC}$ version when handling ontologies
that follow the simple-concept and the simple-role restrictions.
The correctness of this theorem is based on that the method of narrowing down the scope of rule instantiations in Algorithm~$\mathsf{A}_{prc}$
does not influence the determination of the existence of SWD paths. The detailed analysis
can be found in the proof.

\begin{theorem}\label{theorem:aprcpt}
For any DHL$(\circ)$ ontology $\mathcal{O}$ that follows the simple-concept and the simple-role
restrictions,
there exists a poly-logarithmically bounded function $\psi$,
such that Algorithm~$\mathsf{A}_{prc}^{\psi}$ outputs
a materialization graph of $\mathcal{O}$.
\end{theorem}


\section{Evaluation}
\label{sec:evaluation}

In the first part of this section, we analyze different kinds of ontologies and datasets
and investigate the usability of the results proposed above.
In the second part, we evaluate the implementation of Algorithm~$\mathsf{A}_{prc}$
and compare it to the reasoning system RDFox.

\subsection{Practical Usability of the Theoretical Results}

In this part, we analyze different kinds of ontologies and datasets
including benchmarks, real-world ontologies and
datasets that can be expressed in ontology languages.
Based on the analysis of these datasets,
we find that, ignoring imports, many of them
belong to $\mathcal{D}_{\textit{\text{dhl}}}$ or
$\mathcal{D}_{\textit{\text{dhl}}(\circ)}$.

\textbf{Benchmarks}. In the
Semantic Web community, many benchmarks are proposed to
facilitate the evaluation of ontology-based systems
in a standard and systematic way. We investigate several
popular benchmarks using our results and find that
the ontologies used in some benchmarks have simple
structured TBoxes that can be expressed in RDFS
and belong to $\mathcal{D}_{\textit{\text{dhl}}}$.
These benchmarks include SIB\footnote{https://www.w3.org/wiki/Social$\underline{~}$Network$\underline{~}$Intelligence$\underline{~}$BenchMark}
(\emph{Social Network Intelligence BenchMark}),
BSBM\footnote{http://wifo5-03.informatik.uni-mannheim.de/bizer/berlinsparqlbenchmark/}
(\emph{Berlin SPARQL Benchmark}) and
LODIB\footnote{http://wifo5-03.informatik.uni-mannheim.de/bizer/lodib/}
(\emph{Linked Open Data Integration Benchmark}).
The ontology used in IIMB\footnote{http://islab.di.unimi.it/iimb/}
(\emph{The ISLab Instance Matching Benchmark}) follows the simple-concept restriction.

In the latest version of LUBM\footnote{http://swat.cse.lehigh.edu/projects/lubm/}
(The Lehigh University Benchmark),
there are 48 classes and 32 properties.
Statements about properties, such as inverse property statements,
can be rewritten into datalog rules allowed in $\mathcal{D}_{\textit{\text{dhl}}}$.
Most of the statements about classes can be rewritten into datalog rules that
are allowed in $\mathcal{D}_{\textit{\text{dhl}}}$.
Five axioms have, however, the form $A\sqsubseteq\exists R.B$,
which requires existentially quantified variables in the rule head when rewriting
the axiom into a logic rule: $A(x)\rightarrow\exists y(R(x,y)\wedge B(y))$,
where a new anonymous constant $y$ is introduced.
This kind of rule is not considered when using OWL RL reasoners to handle LUBM \cite{UrbaniKMHB12,WeaverH09}.
On the other hand, in some cases, this kind of rule can also be
eliminated when taking a rewriting approach \cite{GrauHKKMMW13}.
In summary, if the above kind of rule is not considered,
the materialization of a LUBM dataset can be handled by Algorithm~$\mathsf{A}_{opt}^{\psi}$.

\textbf{YAGO}. The knowledge base YAGO\footnote{http://www.mpi-inf.mpg.de/home/}
is constructed from Wikipedia and WordNet and the latest version
YAGO3 \cite{MahdisoltaniBS15} has more than 10 million entities
(e.g., persons, organizations, cities, etc.)
and contains more than 120 million facts about these entities.
In order to balance the expressiveness and computing efficiency,
a YAGO-style language, called YAGO \emph{model}, is proposed based on
a slight extension of RDFS \cite{SuchanekKW08}.
In addition to the expressiveness of RDFS,
YAGO \emph{model} also allows stating the \emph{transitivity} and \emph{acyclicity} of a property.
Making full use of RDFS features cannot lead to parallel tractability \cite{Horst05}.
However, in \cite{SuchanekKW08}, a group of materialization rules
is specified, which is more efficient.
All of these rules are allowed in $\mathcal{D}_{\textit{\text{dhl}}}$.
Thus, we have that a well-constructed YAGO dataset belongs to $\mathcal{D}_{\textit{\text{dhl}}}$.

\textbf{Real Ontologies}. We investigated
$151$ ontologies that cover many domains
like biomedicine, geography, etc.
These ontologies are collected
from the Protege ontology library,\footnote{http://protegewiki.stanford.edu/wiki/Protege$\underline{~}$Ontology$\underline{~}$Library}
Swoogle\footnote{http://swoogle.umbc.edu/}
and Oxford ontology lib.\footnote{http://www.cs.ox.ac.uk/isg/ontologies/lib/}
All ontologies are available online.\footnote{https://github.com/quanzz/PT}
Among these ontologies, $111$ of them belong to $\mathcal{D}_{\textit{\text{dhl}}}$
or $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$, and $21$ DHL ontologies contain
conjunctions and follow the simple-concept restriction.
The remaining ontologies have simple TBoxes, i.e., no conjunction ($A_1\sqcap A_2$)
appears in these ontologies.
We also find two DHL($\circ$) ontologies
that follow the simple-role restriction.

The above investigation indicates that the simple-concept and the simple-role restrictions
are allowed in many real applications of different fields.
From the perspective of developers who work on building their own ontologies,
they can also refer to $\mathcal{D}_{\textit{\text{dhl}}}$ and $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$
to achieve the guarantee of the parallel tractability.


\subsection{Evaluating the Implementation of Algorithm~$\mathsf{A}_{prc}$}

We implemented a prototype system ParallelDHL for DHL$(\circ)$ materialization
based on Algorithm~$\mathsf{A}_{prc}$. In this part, we evaluate ParallelDHL and
compare it to the state-of-the-art reasoning system, RDFox \cite{MotikNPHO14},
that can also handle ontology materialization.

\textbf{Datasets}.
We select eight ontologies from the data sources given in the previous subsection;
four of the eight ontologies belong to $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$ and
the rest of them do not follow the simple-concept or the simple-role
restriction.
The eight ontologies are real ontologies and are applied in different fields.
The basic information of these ontologies
is summarized in Table~2 (we use $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$
to denote the complementary set of $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$).

\begin{center}
\begin{tabular}{ccrrc}
\multicolumn{5}{c}{\textbf{Table 2: The Information of the Test Ontologies}}\\
\hline
~~~~~\textbf{Ontology Name}~~~~~&~~~~~\textbf{Field}~~~~~&~~~~~$|\mathcal{T}|+|\mathcal{R}|^a$&~~~~~$|\mathcal{A}|^b$&~~~~~\textbf{Type}$^c$~~~~~\\
\hline

Finance&finance&1,934&6,152&$\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$\\

Molecule&chemistry&43&0&$\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$\\

GrossAnatomy&anatomy&2,276&13&$\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$\\

Skeleton&medicine&815&0&$\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$\\

\hline

ChemistryPrimitive&chemistry&167&0&$\mathcal{D}_{\textit{\text{dhl}}(\circ)}$\\

FacebookOnto&social networking&185&28&$\mathcal{D}_{\textit{\text{dhl}}(\circ)}$\\

Mahabharata&literature&69&2,036&$\mathcal{D}_{\textit{\text{dhl}}(\circ)}$\\

Transportation&traffic&925&511&$\mathcal{D}_{\textit{\text{dhl}}(\circ)}$\\

\hline
\multicolumn{5}{l}{$^a$ \footnotesize$|\mathcal{T}|+|\mathcal{R}|$ denotes the number of axioms occurring in the ontology.}\\

\multicolumn{5}{l}{$^b$ \footnotesize$|\mathcal{A}|$ denotes the number of assertions occurring in the ABox.}\\

\multicolumn{5}{l}{$^c$ \footnotesize$\mathcal{D}_{\textit{\text{dhl}}(\circ)}$ (resp., $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$)
means that the ontology belongs to $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$ (resp., $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$).}\\
\end{tabular}
\label{tab:info}
\end{center}

For the purpose of comparability in the ABox scale, we consider generating ABox assertions
to a limited number with respect to the TBoxes and RBoxes of the test ontologies.
The generation method is based on the work \cite{Elhaik98} where a benchmark generator is proposed
for evaluating ontology-based systems.
For each test ontology, e.g., the ontology Finance, we generate 5 new ontologies with different ABoxes;
these ontologies are denoted by Finance-$i$ ($i\in\{1,2,3,4,5\}$) where $i$ represents that the number
of assertions in the ABox of Finance-$i$ reaches to $i\times100,000$;
we also use ``Finance series" to denote the five generated ontologies
for the ontology Finance. The other test ontologies are processed similarly.


\textbf{The Experimental Results}.
We run ParallelDHL and RDFox over the above eight ontology series respectively.
The running environment is a DELL server with a
memory of 16 GiB and 4 cores.
For fairness, we set the same number of threads (i.e., 1,2,4,6 and 8 threads respectively)
to ParallelDHL and RDFox in each experiment. The results of reasoning
times\footnote{The experimental results can be found at https://github.com/quanzz/PT.} are
presented in the 16 line graphs (denoted by $lg1$,...,$lg16$) of Figure~\ref{fig:linegraph},
where the abscissa of each line graph records the numbers of ABox assertions,
the ordinate records the values of reasoning time (millisecond per unit),
and each of the five curves in different colors denotes the trend of reasoning time with the
corresponding number of threads allocated (we use line-$k$ to denote the curve
corresponding to $k$ threads).

We further process the collected data and fill the results in Table~3, where each cell corresponds
to a test ontology (see the row label) and a new generated ABox (distinguished by the column labels);
the three values from above to below in each cell are: (1) \emph{the minimal time ratio} - the minimal reasoning time
of ParallelDHL devided by the minimal reasoning time of RDFox;
(2) \emph{the average speedup of ParallelDHL};\footnote{Suppose $T_i$ is the reasoning time with $i$ threads allocated,
the average speedup is $\frac{1}{4}(\frac{T_1}{T_2}+\frac{T_2}{T_4}+\frac{T_4}{T_6}+\frac{T_6}{T_8})$.}
(3) \emph{the average speedup of RDFox}.
The minimal time ratio describes the performance of ParallelDHL by using RDFox as the baseline.
The indicator speedup and its derived indicators are the most common tools used for measuring the capacity of parallelism \cite{MotikNPHO14,KazakovKS14,UrbaniKMHB12}.
Here, we use the average speedup \cite{ichiyoshiK92} to describe the average capacity of parallelism with different
threads allocated.
In the following, we give the detailed analysis based on the contents in Figure~\ref{fig:linegraph} and Table~3.


\textbf{The Analysis of the Experimental Results}.
According to the theoretical results in Section~\ref{sec:ptonto}, the ontologies belonging to $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$
may not be parallelly tractable in terms of materialization. In other words,
parallel techniques may not work for improving the efficiency of materialization.
This is shown in the line graphs of Figure~\ref{fig:linegraph}.
We can see that, in the line graphs ($lg1$-$lg8$) of the ontology series
that belong to $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$, the four lines, line-2, line-4, line-6 and line-8,
intersect to some degree. This situation in the line graphs for Finance and GrossAnatomy
series is more obvious. For example, in line graph $lg1$,
line-2 stays higher than line-6, but lower than line-4.
The intersection of lines indicates that reasoning time cannot be obviously reduced with more threads allocated.
This is also supported by the results of the average speedups.
From Table~3, we can see that the average speedups of ParallelDHL and RDFox
for ChemistryPrimitive, FacebookOnto, Mahabharata and Transportation series
are more stable compared with the other ones, i.e., they are averagely 1.4
(it means that the reasoning time can be reduced averagely by 1.4 times with two more threads allocated)
for ParallelDHL, and, 1.1 for RDFox. For the four ontology series that belong to $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$,
the average speedups have a higher volatility. For example,
Finance and Skeleton series lead to high average speedups that reach up to 3,
while, for Molecule and GrossAnatomy series, the average speedups are even lower than 1.
In summary, from the experiments on the test ontology series,
parallelism leads to a more effective improvement for materializing the ontology series
that belong to $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$ compared with the ones in $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$.

By analyzing the experimental results of ParallelDHL and RDFox, we have that
ParallelDHL is a competitive system.
From Table~3, we can find that most of the minimal time ratios are close to 1.
This means that the reasoning times of ParallelDHL are close to that of RDFox in parallel.
In particular, for GrossAnatomy, FacebookOnto and Transportation series, ParallelDHL performs
much better than RDFox; therein, for materializing FacebookOnto-3, ParallelDHL
only costs one fifth of the minimal reasoning time of RDFox.
On the other hand, for most ontology series,
the average speedups of ParallelDHL are overall higher than that of RDFox.
The main difference of ParallelDHL and RDFox lies in that ParallelDHL applies
the optimizations designed for Algorithm~$\mathsf{A}_{opt}$ (see Section~\ref{sec:ptclass}).
The higher average speedups of PrallelDHL also verifies the validity of the optimizations
used in Algorithm~$\mathsf{A}_{opt}$.
One may note that, ParallelDHL is averagely 3 times slower than RDFox when handling Skeleton series.
The main reason is that the computation of \texttt{rch} relations
occupies a large amount of time. We have checked that, the situation of path twisting occurs in Skeleton series.
This makes the the optimization based on \texttt{rch} relations invalid as discussed
in Section~\ref{sec:ptonto}.


\begin{figure}[htbp]
\begin{center}
\includegraphics[width=1.5\textwidth,angle=270]{fig-lineGraph.eps}
\caption{The line graphs of all experiments. The 16 line graphs are labeled by $lg1$,...,$lg16$ respectively.}
\label{fig:linegraph}
\end{center}
\end{figure}

\begin{center}
\begin{tabular}{crrrrr}
\multicolumn{6}{c}{\textbf{Table 3: The Analysis of Reasoning Results}}\\
\hline
&~~~~~~~~~~~~~~~1&~~~~~~~~~~~~~~~2&~~~~~~~~~~~~~~~3&~~~~~~~~~~~~~~~4&~~~~~~~~~~~~~~~5\\
\hline
&0.54&1.36&0.94&0.99&1.70\\
Finance&3.06&1.88&2.29&2.95&2.73\\
&1.01&1.04&1.13&1.11&1.19\\
\hline
&0.94&0.79&0.96&0.98&1.07\\
Molecule&1.04&1.24&1.13&1.07&1.05\\
&0.90&1.03&0.95&1.01&0.99\\
\hline
&0.65&0.48&0.84&0.77&0.83\\
GrossAnatomy&1.41&1.69&1.33&1.32&1.22\\
&0.87&0.99&0.94&0.96&0.98\\
\hline
&1.11&\textbf{3.08}&\textbf{3.03}&\textbf{3.04}&\textbf{2.75}\\
Skeleton&3.28&1.84&1.65&1.74&1.96\\
&1.13&1.01&1.06&1.08&1.08\\
\hline
&1.29&1.54&1.68&1.14&0.93\\
ChemistryPrimitive&\textbf{1.46}&\textbf{1.43}&\textbf{1.44}&\textbf{1.51}&\textbf{1.65}\\
&1.28&1.16&1.14&1.11&1.15\\
\hline
&\textbf{0.23}&\textbf{0.22}&\textbf{0.19}&\textbf{0.24}&\textbf{0.22}\\
FacebookOnto&\textbf{1.81}&\textbf{1.83}&\textbf{1.82}&\textbf{1.61}&\textbf{1.78}\\
&1.22&1.08&1.07&1.09&1.09\\
\hline
&1.19&1.19&0.99&0.84&0.89\\
Mahabharata&\textbf{1.41}&\textbf{1.46}&\textbf{1.51}&\textbf{1.47}&\textbf{1.56}\\
&1.24&1.07&1.13&1.10&1.12\\
\hline
&0.24&0.52&0.51&0.65&0.49\\
Transportation&\textbf{1.98}&\textbf{1.57}&\textbf{1.61}&\textbf{1.55}&\textbf{1.59}\\
&1.14&1.04&1.03&1.08&1.11\\
\hline
\end{tabular}
\label{tab:expresult}
\end{center}

\section{Related Work}
\label{sec:related}

The parallel reasoner RDFox \cite{MotikNPHO14} is used to evaluate our implementation. RDFox is a state-of-the-art system that handles reasoning on datalog rewritable ontology languages. Algorithm~$\mathsf{A}_{bsc}$ proposed in Section~\ref{sec:ptclass} is similar to the main algorithm of RDFox (see \cite{MotikNPHO14}, Sections~3 and 4). The difference lies in that, a group of rule instantiations are handled by one processor (namely a thread) in RDFox, while in Algorithm~$\mathsf{A}_{bsc}$, each rule instantiation is assigned to a unique processor. Thus, in theory, the materialization of the datalog program in Example~\ref{exp:mg} is serial on RDFox. It is also shown from the experiments that parallelism does not lead to a remarkable improvement when RDFox handles the ontology series in $\mathcal{D}^-_{\textit{\text{dhl}}(\circ)}$. We use Algorithm~$\mathsf{A}_{opt}$ to show that the ontology in Example~\ref{exp:mg} is also parallelly tractable. Our implementation ParallelDHL, which is based on Algorithm~$\mathsf{A}_{prc}$, has also been shown to have a better performance than RDFox when handling the test ontologies that belong to $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$.

There is work that studies parallel reasoning in RDFS and OWL. The current methods mainly focus on optimizing reasoning algorithms from different aspects. The authors of \cite{GoodmanJMAAH11} propose a new kind of encoding method for RDF triples to achieve a high performance. This method can significantly yield a throughput improvement and optimize the parallel RDF reasoning and query answering. In the work of \cite{PetersSZ15}, the RETE algorithm is used to accelerate rule matching for RDFS reasoning. The authors of \cite{SubercazeGCL16} propose a more efficient storage technique and optimize the join operations in parallel reasoning. The issue of balance distribution of parallel tasks is also studied \cite{SomaP08,WeaverH09}. Two approaches are explored, i.e., \emph{rule partitioning} (allocating parallel tasks to different processors based on rules) and \emph{data partitioning} (allocating parallel tasks based on data). The evaluation results indicate that the efficiency of balance distribution varies with respect to different datasets. On the other hand, parallel reasoning is also implemented for OWL fragments, e.g., OWL~RL \cite{KolovskiWE10}, OWL~EL \cite{KazakovKS14}, OWL~QL \cite{LemboSS13}, and even highly expressive languages \cite{SteigmillerLG14,LiebigM07,SchlichtS08,WuH12}. In current work, several techniques are proposed to adapt parallel computation to OWL reasoning tasks. A kind of graph-based method is discussed in \cite{LemboSS13} to enhance OWL~QL classification. The authors of \cite{LiebigM07,SchlichtS08,WuH12} propose pruning techniques to optimize the Tableaux algorithm. The \emph{lock-free technique} is applied in the work \cite{KazakovKS14,SteigmillerLG14}.

Another line of optimizing parallel reasoning is to utilize high-performance computing platforms. For in-memory platforms, different supercomputers, like Cray XMT, Yahoo S4, have early been used in parallel RDF reasoning \cite{Hoeksema2011,GoodmanJMAAH11}. The authors of \cite{HeinoP12} report their work on RDFS reasoning based on massively parallel GPU hardware. The distributed parallel platforms, like MapReduce and Peer-to-Peer networks, are also used for RDFS reasoning. The representative systems are WebPIE \cite{UrbaniKMHB12}, Marvin \cite{oren2009marvin} and SAOR \cite{HoganHP09}. Different techniques are discussed in this work to tackle the special problems in distributed computing. However, to study the issue of parallel tractability on distributed platforms, we have to discuss more issues, e.g., \emph{network structures} and \emph{communications}. This is not the focus in this paper.

Different from the above work, the purpose of this paper is to study the issue of the parallel tractability of materialization from the perspective of data. The results given in this paper guarantee the parallel tractability theoretically, regardless of what optimization techniques and platforms as discussed above are used.


\section{Conclusions}
\label{sec:conclusion}

In this paper, we studied the problem of parallel tractability of
materialization on the datalog rewritable ontologies.
To identify the parallelly tractable classes,
we proposed two \texttt{NC} algorithms, Algorithm~$\mathsf{A}_{bsc}^\psi$
and Algorithm~$\mathsf{A}_{opt}^\psi$, that perform materialization on
datalog rewritable ontology languages.
Based on these algorithms, we identified the corresponding
parallelly tractable datalog program (\texttt{PTD}) classes such that materialization
on the datalog programs in these classes is in the complexity class \texttt{NC}.
We further studied two specific ontology languages, DL-Lite and DHL (including one of its extension).
We showed that any ontology expressed in DL-Lite$_{core}$ or DL-Lite$_{\mathcal{R}}$ is parallelly tractable.
For DHL and DHL($\circ$), we proposed two restrictions such that materialization is parallelly tractable.

We verified the usefulness of our theoretical techniques in two ways. On the one hand,
we analyzed different kinds of datasets,
including well-known benchmarks, real-world ontologies and a famous dataset YAGO.
Our analysis showed that many real ontologies belong to
the parallelly tractable class $\mathcal{D}_{\textit{\text{dhl}}}$
or $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$. The
developers and users can also refer to $\mathcal{D}_{\textit{\text{dhl}}}$
and $\mathcal{D}_{\textit{\text{dhl}}(\circ)}$
to create large-scale ontologies for which parallel tractability
is theoretically guaranteed. On the other hand,
we used an optimization strategy based on SWD paths
to give a practical algorithm variant Algorithm~$\mathsf{A}_{prc}$, which can
also be restricted to an \texttt{NC} version, and can be implemented for practice.
We implemented a system based on Algorithm~$\mathsf{A}_{prc}$ and compared it to
the state-of-the-art reasoner RDFox.
The experimental results showed that the optimization proposed in this paper results
in a better performance on parallelly tractable ontologies compared with RDFox.

In the future work, we will extend our work in two lines.
One line is a further study of the parallel tractability of
other expressive ontology languages, in addition to
datalog rewritable ones. Since different expressive OWL languages
have different syntaxes and higher reasoning complexities than \texttt{PTime}-complete, we need to
explore more restrictions that are practical and make materialization
parallelly tractable. Another line of the future work is to
study how to further apply the
results in practice.
One idea is to apply the technique of SWD paths to enhance other reasoning-based tasks,
like ontology classification, ontology debugging and query answering.

\section*{Reference}

\bibliographystyle{elsarticle-num}
\bibliography{reference}



\end{document}
\endinput

%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
%% \appendix

%% \section{}
%% \label{}
